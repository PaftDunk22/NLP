{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d16d58a5",
      "metadata": {
        "id": "d16d58a5"
      },
      "source": [
        "# LV1 – Obrada teksta i Part-of-Speech (POS) označavanje\n",
        "### Laboratorijska vježba 1\n",
        "**Tema:** Osnove obrade prirodnog jezika pomoću biblioteka spaCy i NLTK\n",
        "\n",
        "Ovaj notebook sadrži teorijski uvod, osnovne korake obrade teksta te zadatke za samostalni rad. Studenti mogu birati žele li koristiti *spaCy* ili *NLTK* biblioteku pri rješavanju zadataka."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "728e5e35",
      "metadata": {
        "id": "728e5e35"
      },
      "source": [
        "## Ciljevi vježbe\n",
        "- Upoznati osnovne korake obrade prirodnog jezika (NLP).\n",
        "- Primijeniti biblioteke **spaCy** i **NLTK** na obradu teksta.\n",
        "- Razumjeti i implementirati procese tokenizacije, uklanjanja zaustavnih riječi, lematizacije i POS označavanja.\n",
        "- Razviti sposobnost analize i interpretacije rezultata obrade teksta."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81c3ba0d",
      "metadata": {
        "id": "81c3ba0d"
      },
      "source": [
        "## 1. Instalacija potrebnih biblioteka"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy nltk matplotlib pandas\n",
        "\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import pos_tag\n",
        "\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIIjwtAUhRqm",
        "outputId": "c1aa6b16-3d39-4468-f4d3-4b2c5e0bca14"
      },
      "id": "DIIjwtAUhRqm",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.8)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.8)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.2)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.11.10)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.10.5)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39059489",
      "metadata": {
        "id": "39059489"
      },
      "source": [
        "## 2. Tokenizacija\n",
        "**Opis:** Tokenizacija je proces razdvajanja teksta na manje jedinice – tokene (riječi, interpunkcijske znakove itd.).\n",
        "\n",
        "U nastavku su prikazana dva načina tokenizacije: pomoću *spaCy* i pomoću *NLTK*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a48c5bc1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a48c5bc1",
        "outputId": "3eb54a9a-0539-4500-be25-2a258a8b421a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural\n",
            "Language\n",
            "Processing\n",
            "enables\n",
            "computers\n",
            "to\n",
            "understand\n",
            "human\n",
            "language\n",
            ".\n"
          ]
        }
      ],
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "text = 'Natural Language Processing enables computers to understand human language.'\n",
        "doc = nlp(text)\n",
        "for token in doc:\n",
        "    print(token.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0fee9276",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fee9276",
        "outputId": "8d6e5226-eea9-44a8-bf01-ea3ed0587cf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural', 'Language', 'Processing', 'enables', 'computers', 'to', 'understand', 'human', 'language', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "text = 'Natural Language Processing enables computers to understand human language.'\n",
        "tokens = word_tokenize(text)\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95c3a757",
      "metadata": {
        "id": "95c3a757"
      },
      "source": [
        "### Zadatak 1\n",
        "Upiši vlastiti tekst i izvrši tokenizaciju pomoću obje biblioteke."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "2dd9a883",
      "metadata": {
        "id": "2dd9a883",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc9f98d2-6eba-4e7b-de7a-2d0695df7756"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A\n",
            "VTuber\n",
            "(\n",
            "Japanese\n",
            ":\n",
            "ブイチューバー\n",
            ",\n",
            "Hepburn\n",
            ":\n",
            "BuiChūbā\n",
            ")\n",
            "or\n",
            "virtual\n",
            "YouTuber\n",
            "(\n",
            "バーチャルユーチューバー\n",
            ",\n",
            "bācharu\n",
            "YūChūbā\n",
            ")\n",
            "is\n",
            "an\n",
            "online\n",
            "entertainer\n",
            "who\n",
            "uses\n",
            "a\n",
            "virtual\n",
            "avatar\n",
            "generated\n",
            "using\n",
            "computer\n",
            "graphics\n",
            ".\n",
            "Real\n",
            "-\n",
            "time\n",
            "motion\n",
            "capture\n",
            "software\n",
            "or\n",
            "technology\n",
            "are\n",
            "often\n",
            "—\n",
            "but\n",
            "not\n",
            "always\n",
            "—\n",
            "used\n",
            "to\n",
            "capture\n",
            "movement\n",
            ".\n",
            "The\n",
            "digital\n",
            "trend\n",
            "originated\n",
            "in\n",
            "Japan\n",
            "in\n",
            "the\n",
            "mid-2010s\n",
            ",\n",
            "and\n",
            "has\n",
            "become\n",
            "an\n",
            "international\n",
            "online\n",
            "phenomenon\n",
            "in\n",
            "the\n",
            "2020s\n",
            ".\n",
            "A\n",
            "majority\n",
            "of\n",
            "VTubers\n",
            "are\n",
            "English-\n",
            "and\n",
            "Japanese\n",
            "-\n",
            "speaking\n",
            "YouTubers\n",
            "or\n",
            "live\n",
            "streamers\n",
            "who\n",
            "use\n",
            "avatar\n",
            "designs\n",
            ".\n",
            "By\n",
            "2020\n",
            ",\n",
            "there\n",
            "were\n",
            "more\n",
            "than\n",
            "10,000\n",
            "active\n",
            "VTubers\n",
            ".\n",
            "Although\n",
            "the\n",
            "term\n",
            "is\n",
            "an\n",
            "allusion\n",
            "to\n",
            "the\n",
            "video\n",
            "platform\n",
            "YouTube\n",
            ",\n",
            "they\n",
            "also\n",
            "use\n",
            "websites\n",
            "such\n",
            "as\n",
            "Niconico\n",
            ",\n",
            "Twitch\n",
            ",\n",
            "Facebook\n",
            ",\n",
            "Twitter\n",
            ",\n",
            "and\n",
            "Bilibili\n",
            ".\n",
            "The\n",
            "first\n",
            "entertainer\n",
            "to\n",
            "use\n",
            "the\n",
            "phrase\n",
            "virtual\n",
            "YouTuber\n",
            ",\n",
            "Kizuna\n",
            "AI\n",
            ",\n",
            "began\n",
            "creating\n",
            "content\n",
            "on\n",
            "YouTube\n",
            "in\n",
            "late\n",
            "2016\n",
            ".\n",
            "Her\n",
            "popularity\n",
            "sparked\n",
            "a\n",
            "VTuber\n",
            "trend\n",
            "in\n",
            "Japan\n",
            ",\n",
            "and\n",
            "it\n",
            "spurred\n",
            "the\n",
            "establishment\n",
            "of\n",
            "specialized\n",
            "agencies\n",
            "to\n",
            "promote\n",
            "them\n",
            ",\n",
            "including\n",
            "major\n",
            "ones\n",
            "such\n",
            "as\n",
            "Hololive\n",
            "Production\n",
            "and\n",
            "Nijisanji\n",
            ".\n",
            "Fan\n",
            "translations\n",
            "and\n",
            "foreign\n",
            "-\n",
            "language\n",
            "VTubers\n",
            "have\n",
            "marked\n",
            "a\n",
            "rise\n",
            "in\n",
            "the\n",
            "trend\n",
            "'s\n",
            "international\n",
            "popularity\n",
            ".\n",
            "Virtual\n",
            "YouTubers\n",
            "have\n",
            "appeared\n",
            "in\n",
            "domestic\n",
            "advertising\n",
            "campaigns\n",
            "and\n",
            "have\n",
            "broken\n",
            "livestream\n",
            "-\n",
            "related\n",
            "world\n",
            "records\n",
            ".\n",
            "['A', 'VTuber', '(', 'Japanese', ':', 'ブイチューバー', ',', 'Hepburn', ':', 'BuiChūbā', ')', 'or', 'virtual', 'YouTuber', '(', 'バーチャルユーチューバー', ',', 'bācharu', 'YūChūbā', ')', 'is', 'an', 'online', 'entertainer', 'who', 'uses', 'a', 'virtual', 'avatar', 'generated', 'using', 'computer', 'graphics', '.', 'Real-time', 'motion', 'capture', 'software', 'or', 'technology', 'are', 'often—but', 'not', 'always—used', 'to', 'capture', 'movement', '.', 'The', 'digital', 'trend', 'originated', 'in', 'Japan', 'in', 'the', 'mid-2010s', ',', 'and', 'has', 'become', 'an', 'international', 'online', 'phenomenon', 'in', 'the', '2020s', '.', 'A', 'majority', 'of', 'VTubers', 'are', 'English-', 'and', 'Japanese-speaking', 'YouTubers', 'or', 'live', 'streamers', 'who', 'use', 'avatar', 'designs', '.', 'By', '2020', ',', 'there', 'were', 'more', 'than', '10,000', 'active', 'VTubers', '.', 'Although', 'the', 'term', 'is', 'an', 'allusion', 'to', 'the', 'video', 'platform', 'YouTube', ',', 'they', 'also', 'use', 'websites', 'such', 'as', 'Niconico', ',', 'Twitch', ',', 'Facebook', ',', 'Twitter', ',', 'and', 'Bilibili.The', 'first', 'entertainer', 'to', 'use', 'the', 'phrase', 'virtual', 'YouTuber', ',', 'Kizuna', 'AI', ',', 'began', 'creating', 'content', 'on', 'YouTube', 'in', 'late', '2016', '.', 'Her', 'popularity', 'sparked', 'a', 'VTuber', 'trend', 'in', 'Japan', ',', 'and', 'it', 'spurred', 'the', 'establishment', 'of', 'specialized', 'agencies', 'to', 'promote', 'them', ',', 'including', 'major', 'ones', 'such', 'as', 'Hololive', 'Production', 'and', 'Nijisanji', '.', 'Fan', 'translations', 'and', 'foreign-language', 'VTubers', 'have', 'marked', 'a', 'rise', 'in', 'the', 'trend', \"'s\", 'international', 'popularity', '.', 'Virtual', 'YouTubers', 'have', 'appeared', 'in', 'domestic', 'advertising', 'campaigns', 'and', 'have', 'broken', 'livestream-related', 'world', 'records', '.']\n"
          ]
        }
      ],
      "source": [
        "myText = \"A VTuber (Japanese: ブイチューバー, Hepburn: BuiChūbā) or virtual YouTuber (バーチャルユーチューバー, bācharu YūChūbā) is an online entertainer who uses a virtual avatar generated using computer graphics. Real-time motion capture software or technology are often—but not always—used to capture movement. The digital trend originated in Japan in the mid-2010s, and has become an international online phenomenon in the 2020s. A majority of VTubers are English- and Japanese-speaking YouTubers or live streamers who use avatar designs. By 2020, there were more than 10,000 active VTubers. Although the term is an allusion to the video platform YouTube, they also use websites such as Niconico, Twitch, Facebook, Twitter, and Bilibili.The first entertainer to use the phrase \"\"virtual YouTuber\"\", Kizuna AI, began creating content on YouTube in late 2016. Her popularity sparked a VTuber trend in Japan, and it spurred the establishment of specialized agencies to promote them, including major ones such as Hololive Production and Nijisanji. Fan translations and foreign-language VTubers have marked a rise in the trend's international popularity. Virtual YouTubers have appeared in domestic advertising campaigns and have broken livestream-related world records.\"\n",
        "\n",
        "doc = nlp(myText)\n",
        "for token in doc:\n",
        "    print(token.text)\n",
        "\n",
        "tokens = word_tokenize(myText)\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "051fae1c",
      "metadata": {
        "id": "051fae1c"
      },
      "source": [
        "## 3. Uklanjanje zaustavnih riječi (Stopwords)\n",
        "Zaustavne riječi su česte riječi koje ne doprinose značenju teksta (npr. the, is, in...)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bf13e4d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf13e4d3",
        "outputId": "da7e1ef8-18fe-4d5d-d2d0-1fc2cd8dbecd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural', 'Language', 'Processing', 'enables', 'computers', 'understand', 'human', 'language', '.']\n"
          ]
        }
      ],
      "source": [
        "doc = nlp(text)\n",
        "filtered_spacy = [token.text for token in doc if not token.is_stop]\n",
        "print(filtered_spacy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bcb3dc46",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcb3dc46",
        "outputId": "8641cebd-a8da-4c28-ee81-74199ac6b7aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural', 'Language', 'Processing', 'enables', 'computers', 'understand', 'human', 'language', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_nltk = [word for word in tokens if word.lower() not in stop_words]\n",
        "print(filtered_nltk)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5538038",
      "metadata": {
        "id": "a5538038"
      },
      "source": [
        "### Zadatak 2\n",
        "Ukloni zaustavne riječi iz vlastitog teksta pomoću obje biblioteke."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "37d3c0f3",
      "metadata": {
        "id": "37d3c0f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61ed4f66-6d9e-4f14-e166-4a466da7c466"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['VTuber', '(', 'Japanese', ':', 'ブイチューバー', ',', 'Hepburn', ':', 'BuiChūbā', ')', 'virtual', 'YouTuber', '(', 'バーチャルユーチューバー', ',', 'bācharu', 'YūChūbā', ')', 'online', 'entertainer', 'uses', 'virtual', 'avatar', 'generated', 'computer', 'graphics', '.', 'Real', '-', 'time', 'motion', 'capture', 'software', 'technology', '—', '—', 'capture', 'movement', '.', 'digital', 'trend', 'originated', 'Japan', 'mid-2010s', ',', 'international', 'online', 'phenomenon', '2020s', '.', 'majority', 'VTubers', 'English-', 'Japanese', '-', 'speaking', 'YouTubers', 'live', 'streamers', 'use', 'avatar', 'designs', '.', '2020', ',', '10,000', 'active', 'VTubers', '.', 'term', 'allusion', 'video', 'platform', 'YouTube', ',', 'use', 'websites', 'Niconico', ',', 'Twitch', ',', 'Facebook', ',', 'Twitter', ',', 'Bilibili', '.', 'entertainer', 'use', 'phrase', 'virtual', 'YouTuber', ',', 'Kizuna', 'AI', ',', 'began', 'creating', 'content', 'YouTube', 'late', '2016', '.', 'popularity', 'sparked', 'VTuber', 'trend', 'Japan', ',', 'spurred', 'establishment', 'specialized', 'agencies', 'promote', ',', 'including', 'major', 'ones', 'Hololive', 'Production', 'Nijisanji', '.', 'Fan', 'translations', 'foreign', '-', 'language', 'VTubers', 'marked', 'rise', 'trend', 'international', 'popularity', '.', 'Virtual', 'YouTubers', 'appeared', 'domestic', 'advertising', 'campaigns', 'broken', 'livestream', '-', 'related', 'world', 'records', '.']\n",
            "['VTuber', '(', 'Japanese', ':', 'ブイチューバー', ',', 'Hepburn', ':', 'BuiChūbā', ')', 'virtual', 'YouTuber', '(', 'バーチャルユーチューバー', ',', 'bācharu', 'YūChūbā', ')', 'online', 'entertainer', 'uses', 'virtual', 'avatar', 'generated', 'using', 'computer', 'graphics', '.', 'Real-time', 'motion', 'capture', 'software', 'technology', 'often—but', 'always—used', 'capture', 'movement', '.', 'digital', 'trend', 'originated', 'Japan', 'mid-2010s', ',', 'become', 'international', 'online', 'phenomenon', '2020s', '.', 'majority', 'VTubers', 'English-', 'Japanese-speaking', 'YouTubers', 'live', 'streamers', 'use', 'avatar', 'designs', '.', '2020', ',', '10,000', 'active', 'VTubers', '.', 'Although', 'term', 'allusion', 'video', 'platform', 'YouTube', ',', 'also', 'use', 'websites', 'Niconico', ',', 'Twitch', ',', 'Facebook', ',', 'Twitter', ',', 'Bilibili.The', 'first', 'entertainer', 'use', 'phrase', 'virtual', 'YouTuber', ',', 'Kizuna', 'AI', ',', 'began', 'creating', 'content', 'YouTube', 'late', '2016', '.', 'popularity', 'sparked', 'VTuber', 'trend', 'Japan', ',', 'spurred', 'establishment', 'specialized', 'agencies', 'promote', ',', 'including', 'major', 'ones', 'Hololive', 'Production', 'Nijisanji', '.', 'Fan', 'translations', 'foreign-language', 'VTubers', 'marked', 'rise', 'trend', \"'s\", 'international', 'popularity', '.', 'Virtual', 'YouTubers', 'appeared', 'domestic', 'advertising', 'campaigns', 'broken', 'livestream-related', 'world', 'records', '.']\n"
          ]
        }
      ],
      "source": [
        "doc = nlp(myText)\n",
        "filtered_spacy = [token.text for token in doc if not token.is_stop]\n",
        "print(filtered_spacy)\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_nltk = [word for word in tokens if word.lower() not in stop_words]\n",
        "print(filtered_nltk)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae512ad4",
      "metadata": {
        "id": "ae512ad4"
      },
      "source": [
        "## 4. Lematizacija\n",
        "Lematizacija svodi riječi na osnovni oblik (lemu)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "41ceba60",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41ceba60",
        "outputId": "1228e35f-1d60-4bd4-e2d2-58cd6a95ad8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural         → Natural\n",
            "Language        → Language\n",
            "Processing      → processing\n",
            "enables         → enable\n",
            "computers       → computer\n",
            "to              → to\n",
            "understand      → understand\n",
            "human           → human\n",
            "language        → language\n",
            ".               → .\n"
          ]
        }
      ],
      "source": [
        "#Primjer: Lemmatizacija sa spaCy\n",
        "for token in doc:\n",
        "    print(f'{token.text:15} → {token.lemma_}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "797452a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "797452a0",
        "outputId": "043cb8af-b7ca-4d62-b617-746080134df7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural', 'Language', 'Processing', 'enable', 'computer', 'to', 'understand', 'human', 'language', '.']\n"
          ]
        }
      ],
      "source": [
        "#Primjer: Lemmatizacija s NLTK\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "pos_tags = pos_tag(tokens)\n",
        "def get_wordnet_pos(tag):\n",
        "    if tag.startswith('J'): return wordnet.ADJ\n",
        "    elif tag.startswith('V'): return wordnet.VERB\n",
        "    elif tag.startswith('N'): return wordnet.NOUN\n",
        "    elif tag.startswith('R'): return wordnet.ADV\n",
        "    else: return wordnet.NOUN\n",
        "lemmas = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in pos_tags]\n",
        "print(lemmas)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44f47cbd",
      "metadata": {
        "id": "44f47cbd"
      },
      "source": [
        "### Zadatak 3\n",
        "Primijeni lematizaciju na vlastiti tekst i usporedi rezultate između spaCy i NLTK."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "a357e693",
      "metadata": {
        "id": "a357e693",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "835ad513-866a-4409-c64a-d3222a023c74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A               → a\n",
            "VTuber          → vtuber\n",
            "(               → (\n",
            "Japanese        → Japanese\n",
            ":               → :\n",
            "ブイチューバー         → ブイチューバー\n",
            ",               → ,\n",
            "Hepburn         → Hepburn\n",
            ":               → :\n",
            "BuiChūbā        → BuiChūbā\n",
            ")               → )\n",
            "or              → or\n",
            "virtual         → virtual\n",
            "YouTuber        → YouTuber\n",
            "(               → (\n",
            "バーチャルユーチューバー    → バーチャルユーチューバー\n",
            ",               → ,\n",
            "bācharu         → bācharu\n",
            "YūChūbā         → YūChūbā\n",
            ")               → )\n",
            "is              → be\n",
            "an              → an\n",
            "online          → online\n",
            "entertainer     → entertainer\n",
            "who             → who\n",
            "uses            → use\n",
            "a               → a\n",
            "virtual         → virtual\n",
            "avatar          → avatar\n",
            "generated       → generate\n",
            "using           → use\n",
            "computer        → computer\n",
            "graphics        → graphic\n",
            ".               → .\n",
            "Real            → real\n",
            "-               → -\n",
            "time            → time\n",
            "motion          → motion\n",
            "capture         → capture\n",
            "software        → software\n",
            "or              → or\n",
            "technology      → technology\n",
            "are             → be\n",
            "often           → often\n",
            "—               → —\n",
            "but             → but\n",
            "not             → not\n",
            "always          → always\n",
            "—               → —\n",
            "used            → use\n",
            "to              → to\n",
            "capture         → capture\n",
            "movement        → movement\n",
            ".               → .\n",
            "The             → the\n",
            "digital         → digital\n",
            "trend           → trend\n",
            "originated      → originate\n",
            "in              → in\n",
            "Japan           → Japan\n",
            "in              → in\n",
            "the             → the\n",
            "mid-2010s       → mid-2010\n",
            ",               → ,\n",
            "and             → and\n",
            "has             → have\n",
            "become          → become\n",
            "an              → an\n",
            "international   → international\n",
            "online          → online\n",
            "phenomenon      → phenomenon\n",
            "in              → in\n",
            "the             → the\n",
            "2020s           → 2020\n",
            ".               → .\n",
            "A               → a\n",
            "majority        → majority\n",
            "of              → of\n",
            "VTubers         → VTubers\n",
            "are             → be\n",
            "English-        → english-\n",
            "and             → and\n",
            "Japanese        → Japanese\n",
            "-               → -\n",
            "speaking        → speak\n",
            "YouTubers       → YouTubers\n",
            "or              → or\n",
            "live            → live\n",
            "streamers       → streamer\n",
            "who             → who\n",
            "use             → use\n",
            "avatar          → avatar\n",
            "designs         → design\n",
            ".               → .\n",
            "By              → by\n",
            "2020            → 2020\n",
            ",               → ,\n",
            "there           → there\n",
            "were            → be\n",
            "more            → more\n",
            "than            → than\n",
            "10,000          → 10,000\n",
            "active          → active\n",
            "VTubers         → vtuber\n",
            ".               → .\n",
            "Although        → although\n",
            "the             → the\n",
            "term            → term\n",
            "is              → be\n",
            "an              → an\n",
            "allusion        → allusion\n",
            "to              → to\n",
            "the             → the\n",
            "video           → video\n",
            "platform        → platform\n",
            "YouTube         → YouTube\n",
            ",               → ,\n",
            "they            → they\n",
            "also            → also\n",
            "use             → use\n",
            "websites        → website\n",
            "such            → such\n",
            "as              → as\n",
            "Niconico        → Niconico\n",
            ",               → ,\n",
            "Twitch          → Twitch\n",
            ",               → ,\n",
            "Facebook        → Facebook\n",
            ",               → ,\n",
            "Twitter         → Twitter\n",
            ",               → ,\n",
            "and             → and\n",
            "Bilibili        → Bilibili\n",
            ".               → .\n",
            "The             → the\n",
            "first           → first\n",
            "entertainer     → entertainer\n",
            "to              → to\n",
            "use             → use\n",
            "the             → the\n",
            "phrase          → phrase\n",
            "virtual         → virtual\n",
            "YouTuber        → YouTuber\n",
            ",               → ,\n",
            "Kizuna          → Kizuna\n",
            "AI              → AI\n",
            ",               → ,\n",
            "began           → begin\n",
            "creating        → create\n",
            "content         → content\n",
            "on              → on\n",
            "YouTube         → YouTube\n",
            "in              → in\n",
            "late            → late\n",
            "2016            → 2016\n",
            ".               → .\n",
            "Her             → her\n",
            "popularity      → popularity\n",
            "sparked         → spark\n",
            "a               → a\n",
            "VTuber          → VTuber\n",
            "trend           → trend\n",
            "in              → in\n",
            "Japan           → Japan\n",
            ",               → ,\n",
            "and             → and\n",
            "it              → it\n",
            "spurred         → spur\n",
            "the             → the\n",
            "establishment   → establishment\n",
            "of              → of\n",
            "specialized     → specialized\n",
            "agencies        → agency\n",
            "to              → to\n",
            "promote         → promote\n",
            "them            → they\n",
            ",               → ,\n",
            "including       → include\n",
            "major           → major\n",
            "ones            → one\n",
            "such            → such\n",
            "as              → as\n",
            "Hololive        → Hololive\n",
            "Production      → Production\n",
            "and             → and\n",
            "Nijisanji       → Nijisanji\n",
            ".               → .\n",
            "Fan             → fan\n",
            "translations    → translation\n",
            "and             → and\n",
            "foreign         → foreign\n",
            "-               → -\n",
            "language        → language\n",
            "VTubers         → vtuber\n",
            "have            → have\n",
            "marked          → mark\n",
            "a               → a\n",
            "rise            → rise\n",
            "in              → in\n",
            "the             → the\n",
            "trend           → trend\n",
            "'s              → 's\n",
            "international   → international\n",
            "popularity      → popularity\n",
            ".               → .\n",
            "Virtual         → virtual\n",
            "YouTubers       → YouTubers\n",
            "have            → have\n",
            "appeared        → appear\n",
            "in              → in\n",
            "domestic        → domestic\n",
            "advertising     → advertising\n",
            "campaigns       → campaign\n",
            "and             → and\n",
            "have            → have\n",
            "broken          → break\n",
            "livestream      → livestream\n",
            "-               → -\n",
            "related         → relate\n",
            "world           → world\n",
            "records         → record\n",
            ".               → .\n",
            "['A', 'VTuber', '(', 'Japanese', ':', 'ブイチューバー', ',', 'Hepburn', ':', 'BuiChūbā', ')', 'or', 'virtual', 'YouTuber', '(', 'バーチャルユーチューバー', ',', 'bācharu', 'YūChūbā', ')', 'be', 'an', 'online', 'entertainer', 'who', 'use', 'a', 'virtual', 'avatar', 'generate', 'use', 'computer', 'graphic', '.', 'Real-time', 'motion', 'capture', 'software', 'or', 'technology', 'be', 'often—but', 'not', 'always—used', 'to', 'capture', 'movement', '.', 'The', 'digital', 'trend', 'originate', 'in', 'Japan', 'in', 'the', 'mid-2010s', ',', 'and', 'have', 'become', 'an', 'international', 'online', 'phenomenon', 'in', 'the', '2020s', '.', 'A', 'majority', 'of', 'VTubers', 'be', 'English-', 'and', 'Japanese-speaking', 'YouTubers', 'or', 'live', 'streamer', 'who', 'use', 'avatar', 'design', '.', 'By', '2020', ',', 'there', 'be', 'more', 'than', '10,000', 'active', 'VTubers', '.', 'Although', 'the', 'term', 'be', 'an', 'allusion', 'to', 'the', 'video', 'platform', 'YouTube', ',', 'they', 'also', 'use', 'website', 'such', 'a', 'Niconico', ',', 'Twitch', ',', 'Facebook', ',', 'Twitter', ',', 'and', 'Bilibili.The', 'first', 'entertainer', 'to', 'use', 'the', 'phrase', 'virtual', 'YouTuber', ',', 'Kizuna', 'AI', ',', 'begin', 'create', 'content', 'on', 'YouTube', 'in', 'late', '2016', '.', 'Her', 'popularity', 'spark', 'a', 'VTuber', 'trend', 'in', 'Japan', ',', 'and', 'it', 'spur', 'the', 'establishment', 'of', 'specialized', 'agency', 'to', 'promote', 'them', ',', 'include', 'major', 'one', 'such', 'a', 'Hololive', 'Production', 'and', 'Nijisanji', '.', 'Fan', 'translation', 'and', 'foreign-language', 'VTubers', 'have', 'mark', 'a', 'rise', 'in', 'the', 'trend', \"'s\", 'international', 'popularity', '.', 'Virtual', 'YouTubers', 'have', 'appear', 'in', 'domestic', 'advertising', 'campaign', 'and', 'have', 'break', 'livestream-related', 'world', 'record', '.']\n"
          ]
        }
      ],
      "source": [
        "for token in doc:\n",
        "    print(f'{token.text:15} → {token.lemma_}')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "pos_tags = pos_tag(tokens)\n",
        "def get_wordnet_pos(tag):\n",
        "    if tag.startswith('J'): return wordnet.ADJ\n",
        "    elif tag.startswith('V'): return wordnet.VERB\n",
        "    elif tag.startswith('N'): return wordnet.NOUN\n",
        "    elif tag.startswith('R'): return wordnet.ADV\n",
        "    else: return wordnet.NOUN\n",
        "lemmas = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in pos_tags]\n",
        "print(lemmas)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1f1b920",
      "metadata": {
        "id": "e1f1b920"
      },
      "source": [
        "## 5. POS (Part-of-Speech) označavanje\n",
        "POS označavanje dodjeljuje gramatičku ulogu svakoj riječi (imenica, glagol, pridjev, prilog...)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b25fb76c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b25fb76c",
        "outputId": "4be9f823-633c-4d44-8488-97c95164e43f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural         → PROPN  (NNP)\n",
            "Language        → PROPN  (NNP)\n",
            "Processing      → NOUN   (NN)\n",
            "enables         → VERB   (VBZ)\n",
            "computers       → NOUN   (NNS)\n",
            "to              → PART   (TO)\n",
            "understand      → VERB   (VB)\n",
            "human           → ADJ    (JJ)\n",
            "language        → NOUN   (NN)\n",
            ".               → PUNCT  (.)\n"
          ]
        }
      ],
      "source": [
        "for token in doc:\n",
        "    print(f'{token.text:15} → {token.pos_:6} ({token.tag_})')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "fe46861f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe46861f",
        "outputId": "e72bbb33-e7f1-441f-8ced-17b0674ca59b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural         → JJ\n",
            "Language        → NNP\n",
            "Processing      → NNP\n",
            "enables         → VBZ\n",
            "computers       → NNS\n",
            "to              → TO\n",
            "understand      → VB\n",
            "human           → JJ\n",
            "language        → NN\n",
            ".               → .\n"
          ]
        }
      ],
      "source": [
        "pos_tags = pos_tag(tokens)\n",
        "for word, tag in pos_tags:\n",
        "    print(f'{word:15} → {tag}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3de5688",
      "metadata": {
        "id": "a3de5688"
      },
      "source": [
        "### Zadatak 4\n",
        "Izdvoji sve imenice i glagole iz svog teksta pomoću jedne od biblioteka."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "d93a5e36",
      "metadata": {
        "id": "d93a5e36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6e268df-d1dc-485e-8c58-9bab3a0ed408"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A               → DET    (DT)\n",
            "VTuber          → NOUN   (NN)\n",
            "(               → PUNCT  (-LRB-)\n",
            "Japanese        → PROPN  (NNP)\n",
            ":               → PUNCT  (:)\n",
            "ブイチューバー         → VERB   (VB)\n",
            ",               → PUNCT  (,)\n",
            "Hepburn         → PROPN  (NNP)\n",
            ":               → PUNCT  (:)\n",
            "BuiChūbā        → PROPN  (NNP)\n",
            ")               → PUNCT  (-RRB-)\n",
            "or              → CCONJ  (CC)\n",
            "virtual         → ADJ    (JJ)\n",
            "YouTuber        → PROPN  (NNP)\n",
            "(               → PUNCT  (-LRB-)\n",
            "バーチャルユーチューバー    → PROPN  (NNP)\n",
            ",               → PUNCT  (,)\n",
            "bācharu         → PROPN  (NNP)\n",
            "YūChūbā         → PROPN  (NNP)\n",
            ")               → PUNCT  (-RRB-)\n",
            "is              → AUX    (VBZ)\n",
            "an              → DET    (DT)\n",
            "online          → ADJ    (JJ)\n",
            "entertainer     → NOUN   (NN)\n",
            "who             → PRON   (WP)\n",
            "uses            → VERB   (VBZ)\n",
            "a               → DET    (DT)\n",
            "virtual         → ADJ    (JJ)\n",
            "avatar          → NOUN   (NN)\n",
            "generated       → VERB   (VBN)\n",
            "using           → VERB   (VBG)\n",
            "computer        → NOUN   (NN)\n",
            "graphics        → NOUN   (NNS)\n",
            ".               → PUNCT  (.)\n",
            "Real            → ADJ    (JJ)\n",
            "-               → PUNCT  (HYPH)\n",
            "time            → NOUN   (NN)\n",
            "motion          → NOUN   (NN)\n",
            "capture         → NOUN   (NN)\n",
            "software        → NOUN   (NN)\n",
            "or              → CCONJ  (CC)\n",
            "technology      → NOUN   (NN)\n",
            "are             → AUX    (VBP)\n",
            "often           → ADV    (RB)\n",
            "—               → PUNCT  (:)\n",
            "but             → CCONJ  (CC)\n",
            "not             → PART   (RB)\n",
            "always          → ADV    (RB)\n",
            "—               → PUNCT  (:)\n",
            "used            → VERB   (VBN)\n",
            "to              → PART   (TO)\n",
            "capture         → VERB   (VB)\n",
            "movement        → NOUN   (NN)\n",
            ".               → PUNCT  (.)\n",
            "The             → DET    (DT)\n",
            "digital         → ADJ    (JJ)\n",
            "trend           → NOUN   (NN)\n",
            "originated      → VERB   (VBD)\n",
            "in              → ADP    (IN)\n",
            "Japan           → PROPN  (NNP)\n",
            "in              → ADP    (IN)\n",
            "the             → DET    (DT)\n",
            "mid-2010s       → NOUN   (NNS)\n",
            ",               → PUNCT  (,)\n",
            "and             → CCONJ  (CC)\n",
            "has             → AUX    (VBZ)\n",
            "become          → VERB   (VBN)\n",
            "an              → DET    (DT)\n",
            "international   → ADJ    (JJ)\n",
            "online          → ADJ    (JJ)\n",
            "phenomenon      → NOUN   (NN)\n",
            "in              → ADP    (IN)\n",
            "the             → DET    (DT)\n",
            "2020s           → NOUN   (NNS)\n",
            ".               → PUNCT  (.)\n",
            "A               → DET    (DT)\n",
            "majority        → NOUN   (NN)\n",
            "of              → ADP    (IN)\n",
            "VTubers         → PROPN  (NNPS)\n",
            "are             → AUX    (VBP)\n",
            "English-        → NOUN   (NN)\n",
            "and             → CCONJ  (CC)\n",
            "Japanese        → PROPN  (NNP)\n",
            "-               → PUNCT  (HYPH)\n",
            "speaking        → VERB   (VBG)\n",
            "YouTubers       → PROPN  (NNPS)\n",
            "or              → CCONJ  (CC)\n",
            "live            → ADJ    (JJ)\n",
            "streamers       → NOUN   (NNS)\n",
            "who             → PRON   (WP)\n",
            "use             → VERB   (VBP)\n",
            "avatar          → ADJ    (JJ)\n",
            "designs         → NOUN   (NNS)\n",
            ".               → PUNCT  (.)\n",
            "By              → ADP    (IN)\n",
            "2020            → NUM    (CD)\n",
            ",               → PUNCT  (,)\n",
            "there           → PRON   (EX)\n",
            "were            → VERB   (VBD)\n",
            "more            → ADJ    (JJR)\n",
            "than            → ADP    (IN)\n",
            "10,000          → NUM    (CD)\n",
            "active          → ADJ    (JJ)\n",
            "VTubers         → NOUN   (NNS)\n",
            ".               → PUNCT  (.)\n",
            "Although        → SCONJ  (IN)\n",
            "the             → DET    (DT)\n",
            "term            → NOUN   (NN)\n",
            "is              → AUX    (VBZ)\n",
            "an              → DET    (DT)\n",
            "allusion        → NOUN   (NN)\n",
            "to              → ADP    (IN)\n",
            "the             → DET    (DT)\n",
            "video           → NOUN   (NN)\n",
            "platform        → NOUN   (NN)\n",
            "YouTube         → PROPN  (NNP)\n",
            ",               → PUNCT  (,)\n",
            "they            → PRON   (PRP)\n",
            "also            → ADV    (RB)\n",
            "use             → VERB   (VBP)\n",
            "websites        → NOUN   (NNS)\n",
            "such            → ADJ    (JJ)\n",
            "as              → ADP    (IN)\n",
            "Niconico        → PROPN  (NNP)\n",
            ",               → PUNCT  (,)\n",
            "Twitch          → PROPN  (NNP)\n",
            ",               → PUNCT  (,)\n",
            "Facebook        → PROPN  (NNP)\n",
            ",               → PUNCT  (,)\n",
            "Twitter         → PROPN  (NNP)\n",
            ",               → PUNCT  (,)\n",
            "and             → CCONJ  (CC)\n",
            "Bilibili        → PROPN  (NNP)\n",
            ".               → PUNCT  (.)\n",
            "The             → DET    (DT)\n",
            "first           → ADJ    (JJ)\n",
            "entertainer     → NOUN   (NN)\n",
            "to              → PART   (TO)\n",
            "use             → VERB   (VB)\n",
            "the             → DET    (DT)\n",
            "phrase          → NOUN   (NN)\n",
            "virtual         → ADJ    (JJ)\n",
            "YouTuber        → PROPN  (NNP)\n",
            ",               → PUNCT  (,)\n",
            "Kizuna          → PROPN  (NNP)\n",
            "AI              → PROPN  (NNP)\n",
            ",               → PUNCT  (,)\n",
            "began           → VERB   (VBD)\n",
            "creating        → VERB   (VBG)\n",
            "content         → NOUN   (NN)\n",
            "on              → ADP    (IN)\n",
            "YouTube         → PROPN  (NNP)\n",
            "in              → ADP    (IN)\n",
            "late            → ADJ    (JJ)\n",
            "2016            → NUM    (CD)\n",
            ".               → PUNCT  (.)\n",
            "Her             → PRON   (PRP$)\n",
            "popularity      → NOUN   (NN)\n",
            "sparked         → VERB   (VBD)\n",
            "a               → DET    (DT)\n",
            "VTuber          → PROPN  (NNP)\n",
            "trend           → NOUN   (NN)\n",
            "in              → ADP    (IN)\n",
            "Japan           → PROPN  (NNP)\n",
            ",               → PUNCT  (,)\n",
            "and             → CCONJ  (CC)\n",
            "it              → PRON   (PRP)\n",
            "spurred         → VERB   (VBD)\n",
            "the             → DET    (DT)\n",
            "establishment   → NOUN   (NN)\n",
            "of              → ADP    (IN)\n",
            "specialized     → ADJ    (JJ)\n",
            "agencies        → NOUN   (NNS)\n",
            "to              → PART   (TO)\n",
            "promote         → VERB   (VB)\n",
            "them            → PRON   (PRP)\n",
            ",               → PUNCT  (,)\n",
            "including       → VERB   (VBG)\n",
            "major           → ADJ    (JJ)\n",
            "ones            → NOUN   (NNS)\n",
            "such            → ADJ    (JJ)\n",
            "as              → ADP    (IN)\n",
            "Hololive        → PROPN  (NNP)\n",
            "Production      → PROPN  (NNP)\n",
            "and             → CCONJ  (CC)\n",
            "Nijisanji       → PROPN  (NNP)\n",
            ".               → PUNCT  (.)\n",
            "Fan             → ADJ    (JJ)\n",
            "translations    → NOUN   (NNS)\n",
            "and             → CCONJ  (CC)\n",
            "foreign         → ADJ    (JJ)\n",
            "-               → PUNCT  (HYPH)\n",
            "language        → NOUN   (NN)\n",
            "VTubers         → NOUN   (NNS)\n",
            "have            → AUX    (VBP)\n",
            "marked          → VERB   (VBN)\n",
            "a               → DET    (DT)\n",
            "rise            → NOUN   (NN)\n",
            "in              → ADP    (IN)\n",
            "the             → DET    (DT)\n",
            "trend           → NOUN   (NN)\n",
            "'s              → PART   (POS)\n",
            "international   → ADJ    (JJ)\n",
            "popularity      → NOUN   (NN)\n",
            ".               → PUNCT  (.)\n",
            "Virtual         → ADJ    (JJ)\n",
            "YouTubers       → PROPN  (NNPS)\n",
            "have            → AUX    (VBP)\n",
            "appeared        → VERB   (VBN)\n",
            "in              → ADP    (IN)\n",
            "domestic        → ADJ    (JJ)\n",
            "advertising     → NOUN   (NN)\n",
            "campaigns       → NOUN   (NNS)\n",
            "and             → CCONJ  (CC)\n",
            "have            → AUX    (VBP)\n",
            "broken          → VERB   (VBN)\n",
            "livestream      → NOUN   (NN)\n",
            "-               → PUNCT  (HYPH)\n",
            "related         → VERB   (VBN)\n",
            "world           → NOUN   (NN)\n",
            "records         → NOUN   (NNS)\n",
            ".               → PUNCT  (.)\n"
          ]
        }
      ],
      "source": [
        "for token in doc:\n",
        "    print(f'{token.text:15} → {token.pos_:6} ({token.tag_})')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b5de9a2",
      "metadata": {
        "id": "6b5de9a2"
      },
      "source": [
        "## 6. Zadaci"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47b84243",
      "metadata": {
        "id": "47b84243"
      },
      "source": [
        "## Zadatak 1: Usporedi dva teksta po učestalosti riječi\n",
        "\n",
        "**Opis:**  \n",
        "Analiziraj dva različita teksta (npr. jedan o sportu, drugi o tehnologiji).  \n",
        "Nakon što provedeš tokenizaciju, uklanjanje zaustavnih riječi i lematizaciju, potrebno je:  \n",
        "- pronaći 5 najčešćih imenica u svakom tekstu,  \n",
        "- usporediti liste dobivenih imenica,  \n",
        "- zaključiti o čemu se govori u svakom tekstu.\n",
        "\n",
        "**Cilj:**  \n",
        "Razumjeti kako se analiza frekvencije riječi može koristiti za prepoznavanje teme teksta.\n",
        "\n",
        "**Upute:**  \n",
        "1. Učitaj dva različita teksta (mogu biti dvije rečenice, dva odlomka ili datoteke).  \n",
        "2. Obradi svaki tekst (tokenizacija → čišćenje → lematizacija → POS tagging).  \n",
        "3. Izdvoji samo riječi označene kao NOUN (imenice).  \n",
        "4. Prebroji pojavljivanja i prikaži 5 najčešćih.  \n",
        "5. Zaključi koja je tema svakog teksta."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_sport = \"\"\"\n",
        "The team played an intense match last night, delivering one of their strongest performances this season.\n",
        "Throughout the match, the team demonstrated exceptional teamwork, discipline, and determination.\n",
        "The coach repeatedly emphasized how important teamwork was for maintaining control during the most difficult moments of the match.\n",
        "Several players mentioned that the team had trained specifically to improve their teamwork and communication, which clearly paid off.\n",
        "Fans celebrated loudly after the match, recognizing that the team’s victory was crucial for improving their position in the championship.\n",
        "During the press conference, the coach praised the players for their strategy, dedication, and ability to adapt as the match progressed.\n",
        "He highlighted that every victory strengthens the team’s confidence and prepares them for future challenges.\n",
        "The upcoming match is even more important, as the team is competing for a spot in the finals.\n",
        "Analysts agree that if the team continues to show this level of teamwork and discipline, they have a strong chance of winning the entire championship.\n",
        "In the end, the team proved that success is not just about individual talent but about unity, effort, and the shared goal of winning the championship.\n",
        "\"\"\"\n",
        "\n",
        "text_tech = \"\"\"\n",
        "Modern technology is evolving rapidly, shaping the way people work, communicate, and solve complex problems.\n",
        "New devices and software are developed every year, pushing the boundaries of what modern technology can achieve.\n",
        "Researchers are focusing heavily on artificial intelligence, automation, and advanced data processing to create smarter and more powerful systems.\n",
        "These innovations enable companies to build faster devices, more secure software, and highly efficient solutions for everyday use.\n",
        "Experts believe that artificial intelligence will continue to transform technology by improving decision-making, optimizing workflows, and predicting user needs.\n",
        "Many companies are investing in automation technologies to reduce costs, increase productivity, and eliminate repetitive tasks.\n",
        "At the same time, advancements in data processing make it possible to analyze enormous datasets and identify patterns that were previously impossible to detect.\n",
        "This combination of artificial intelligence, automation, and data processing is driving a new era of modern technology.\n",
        "If current trends continue, technology will become even more integrated into daily life, offering smarter devices, adaptive software, and personalized solutions.\n",
        "Researchers conclude that the future of modern technology depends on continuous innovation, reliable data processing, and the responsible development of artificial intelligence.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "SQXDyoqIBhln"
      },
      "id": "SQXDyoqIBhln",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_sport = nlp(text_sport)\n",
        "for token in doc_sport:\n",
        "    print(token.text)\n",
        "\n",
        "doc_tech = nlp(text_tech)\n",
        "for token in doc_tech:\n",
        "    print(token.text)\n",
        "\n",
        "filtered_sport = [token.text for token in doc_sport if not token.is_stop]\n",
        "print(filtered_sport)\n",
        "\n",
        "filtered_tech = [token.text for token in doc_tech if not token.is_stop]\n",
        "print(filtered_sport)\n",
        "\n",
        "for token in doc_sport:\n",
        "    print(f'{token.text:15} → {token.lemma_}')\n",
        "\n",
        "\n",
        "for token in doc_tech:\n",
        "  print(f'{token.text:15} → {token.lemma_}')\n",
        "\n",
        "sport_nouns=[]\n",
        "tech_nouns=[]\n",
        "\n",
        "for token in doc_sport:\n",
        "    print(f'{token.text:15} → {token.pos_:6} ({token.tag_})')\n",
        "    if(token.pos_ == \"NOUN\"):\n",
        "      sport_nouns.append(token.lemma_)\n",
        "\n",
        "for token in doc_tech:\n",
        "    print(f'{token.text:15} → {token.pos_:6} ({token.tag_})')\n",
        "    if(token.pos_ == \"NOUN\"):\n",
        "      tech_nouns.append(token.lemma_)\n",
        "\n",
        "print(\"Sport NOUNS:\")\n",
        "print(sport_nouns)\n",
        "\n",
        "print(\"Tech NOUNS:\")\n",
        "print(tech_nouns)\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "sport_counter = Counter(sport_nouns)\n",
        "tech_counter = Counter(tech_nouns)\n",
        "\n",
        "print(\"sport:\")\n",
        "print(sport_counter)\n",
        "print(\"tech:\")\n",
        "print(tech_counter)\n",
        "\n",
        "top5_sport = sport_counter.most_common(5)\n",
        "top5_tech = tech_counter.most_common(5)\n",
        "\n",
        "print(\"top 5 sport:\")\n",
        "print(top5_sport)\n",
        "print(\"top 5 tech:\")\n",
        "print(top5_tech)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Xa_7h5RKO3R",
        "outputId": "8314832c-6f44-4db3-b739-8b8822310cb7"
      },
      "id": "_Xa_7h5RKO3R",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "The\n",
            "team\n",
            "played\n",
            "an\n",
            "intense\n",
            "match\n",
            "last\n",
            "night\n",
            ",\n",
            "delivering\n",
            "one\n",
            "of\n",
            "their\n",
            "strongest\n",
            "performances\n",
            "this\n",
            "season\n",
            ".\n",
            "\n",
            "\n",
            "Throughout\n",
            "the\n",
            "match\n",
            ",\n",
            "the\n",
            "team\n",
            "demonstrated\n",
            "exceptional\n",
            "teamwork\n",
            ",\n",
            "discipline\n",
            ",\n",
            "and\n",
            "determination\n",
            ".\n",
            "\n",
            "\n",
            "The\n",
            "coach\n",
            "repeatedly\n",
            "emphasized\n",
            "how\n",
            "important\n",
            "teamwork\n",
            "was\n",
            "for\n",
            "maintaining\n",
            "control\n",
            "during\n",
            "the\n",
            "most\n",
            "difficult\n",
            "moments\n",
            "of\n",
            "the\n",
            "match\n",
            ".\n",
            "\n",
            "\n",
            "Several\n",
            "players\n",
            "mentioned\n",
            "that\n",
            "the\n",
            "team\n",
            "had\n",
            "trained\n",
            "specifically\n",
            "to\n",
            "improve\n",
            "their\n",
            "teamwork\n",
            "and\n",
            "communication\n",
            ",\n",
            "which\n",
            "clearly\n",
            "paid\n",
            "off\n",
            ".\n",
            "\n",
            "\n",
            "Fans\n",
            "celebrated\n",
            "loudly\n",
            "after\n",
            "the\n",
            "match\n",
            ",\n",
            "recognizing\n",
            "that\n",
            "the\n",
            "team\n",
            "’s\n",
            "victory\n",
            "was\n",
            "crucial\n",
            "for\n",
            "improving\n",
            "their\n",
            "position\n",
            "in\n",
            "the\n",
            "championship\n",
            ".\n",
            "\n",
            "\n",
            "During\n",
            "the\n",
            "press\n",
            "conference\n",
            ",\n",
            "the\n",
            "coach\n",
            "praised\n",
            "the\n",
            "players\n",
            "for\n",
            "their\n",
            "strategy\n",
            ",\n",
            "dedication\n",
            ",\n",
            "and\n",
            "ability\n",
            "to\n",
            "adapt\n",
            "as\n",
            "the\n",
            "match\n",
            "progressed\n",
            ".\n",
            "\n",
            "\n",
            "He\n",
            "highlighted\n",
            "that\n",
            "every\n",
            "victory\n",
            "strengthens\n",
            "the\n",
            "team\n",
            "’s\n",
            "confidence\n",
            "and\n",
            "prepares\n",
            "them\n",
            "for\n",
            "future\n",
            "challenges\n",
            ".\n",
            "\n",
            "\n",
            "The\n",
            "upcoming\n",
            "match\n",
            "is\n",
            "even\n",
            "more\n",
            "important\n",
            ",\n",
            "as\n",
            "the\n",
            "team\n",
            "is\n",
            "competing\n",
            "for\n",
            "a\n",
            "spot\n",
            "in\n",
            "the\n",
            "finals\n",
            ".\n",
            "\n",
            "\n",
            "Analysts\n",
            "agree\n",
            "that\n",
            "if\n",
            "the\n",
            "team\n",
            "continues\n",
            "to\n",
            "show\n",
            "this\n",
            "level\n",
            "of\n",
            "teamwork\n",
            "and\n",
            "discipline\n",
            ",\n",
            "they\n",
            "have\n",
            "a\n",
            "strong\n",
            "chance\n",
            "of\n",
            "winning\n",
            "the\n",
            "entire\n",
            "championship\n",
            ".\n",
            "\n",
            "\n",
            "In\n",
            "the\n",
            "end\n",
            ",\n",
            "the\n",
            "team\n",
            "proved\n",
            "that\n",
            "success\n",
            "is\n",
            "not\n",
            "just\n",
            "about\n",
            "individual\n",
            "talent\n",
            "but\n",
            "about\n",
            "unity\n",
            ",\n",
            "effort\n",
            ",\n",
            "and\n",
            "the\n",
            "shared\n",
            "goal\n",
            "of\n",
            "winning\n",
            "the\n",
            "championship\n",
            ".\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Modern\n",
            "technology\n",
            "is\n",
            "evolving\n",
            "rapidly\n",
            ",\n",
            "shaping\n",
            "the\n",
            "way\n",
            "people\n",
            "work\n",
            ",\n",
            "communicate\n",
            ",\n",
            "and\n",
            "solve\n",
            "complex\n",
            "problems\n",
            ".\n",
            "\n",
            "\n",
            "New\n",
            "devices\n",
            "and\n",
            "software\n",
            "are\n",
            "developed\n",
            "every\n",
            "year\n",
            ",\n",
            "pushing\n",
            "the\n",
            "boundaries\n",
            "of\n",
            "what\n",
            "modern\n",
            "technology\n",
            "can\n",
            "achieve\n",
            ".\n",
            "\n",
            "\n",
            "Researchers\n",
            "are\n",
            "focusing\n",
            "heavily\n",
            "on\n",
            "artificial\n",
            "intelligence\n",
            ",\n",
            "automation\n",
            ",\n",
            "and\n",
            "advanced\n",
            "data\n",
            "processing\n",
            "to\n",
            "create\n",
            "smarter\n",
            "and\n",
            "more\n",
            "powerful\n",
            "systems\n",
            ".\n",
            "\n",
            "\n",
            "These\n",
            "innovations\n",
            "enable\n",
            "companies\n",
            "to\n",
            "build\n",
            "faster\n",
            "devices\n",
            ",\n",
            "more\n",
            "secure\n",
            "software\n",
            ",\n",
            "and\n",
            "highly\n",
            "efficient\n",
            "solutions\n",
            "for\n",
            "everyday\n",
            "use\n",
            ".\n",
            "\n",
            "\n",
            "Experts\n",
            "believe\n",
            "that\n",
            "artificial\n",
            "intelligence\n",
            "will\n",
            "continue\n",
            "to\n",
            "transform\n",
            "technology\n",
            "by\n",
            "improving\n",
            "decision\n",
            "-\n",
            "making\n",
            ",\n",
            "optimizing\n",
            "workflows\n",
            ",\n",
            "and\n",
            "predicting\n",
            "user\n",
            "needs\n",
            ".\n",
            "\n",
            "\n",
            "Many\n",
            "companies\n",
            "are\n",
            "investing\n",
            "in\n",
            "automation\n",
            "technologies\n",
            "to\n",
            "reduce\n",
            "costs\n",
            ",\n",
            "increase\n",
            "productivity\n",
            ",\n",
            "and\n",
            "eliminate\n",
            "repetitive\n",
            "tasks\n",
            ".\n",
            "\n",
            "\n",
            "At\n",
            "the\n",
            "same\n",
            "time\n",
            ",\n",
            "advancements\n",
            "in\n",
            "data\n",
            "processing\n",
            "make\n",
            "it\n",
            "possible\n",
            "to\n",
            "analyze\n",
            "enormous\n",
            "datasets\n",
            "and\n",
            "identify\n",
            "patterns\n",
            "that\n",
            "were\n",
            "previously\n",
            "impossible\n",
            "to\n",
            "detect\n",
            ".\n",
            "\n",
            "\n",
            "This\n",
            "combination\n",
            "of\n",
            "artificial\n",
            "intelligence\n",
            ",\n",
            "automation\n",
            ",\n",
            "and\n",
            "data\n",
            "processing\n",
            "is\n",
            "driving\n",
            "a\n",
            "new\n",
            "era\n",
            "of\n",
            "modern\n",
            "technology\n",
            ".\n",
            "\n",
            "\n",
            "If\n",
            "current\n",
            "trends\n",
            "continue\n",
            ",\n",
            "technology\n",
            "will\n",
            "become\n",
            "even\n",
            "more\n",
            "integrated\n",
            "into\n",
            "daily\n",
            "life\n",
            ",\n",
            "offering\n",
            "smarter\n",
            "devices\n",
            ",\n",
            "adaptive\n",
            "software\n",
            ",\n",
            "and\n",
            "personalized\n",
            "solutions\n",
            ".\n",
            "\n",
            "\n",
            "Researchers\n",
            "conclude\n",
            "that\n",
            "the\n",
            "future\n",
            "of\n",
            "modern\n",
            "technology\n",
            "depends\n",
            "on\n",
            "continuous\n",
            "innovation\n",
            ",\n",
            "reliable\n",
            "data\n",
            "processing\n",
            ",\n",
            "and\n",
            "the\n",
            "responsible\n",
            "development\n",
            "of\n",
            "artificial\n",
            "intelligence\n",
            ".\n",
            "\n",
            "\n",
            "['\\n', 'team', 'played', 'intense', 'match', 'night', ',', 'delivering', 'strongest', 'performances', 'season', '.', '\\n', 'match', ',', 'team', 'demonstrated', 'exceptional', 'teamwork', ',', 'discipline', ',', 'determination', '.', '\\n', 'coach', 'repeatedly', 'emphasized', 'important', 'teamwork', 'maintaining', 'control', 'difficult', 'moments', 'match', '.', '\\n', 'players', 'mentioned', 'team', 'trained', 'specifically', 'improve', 'teamwork', 'communication', ',', 'clearly', 'paid', '.', '\\n', 'Fans', 'celebrated', 'loudly', 'match', ',', 'recognizing', 'team', 'victory', 'crucial', 'improving', 'position', 'championship', '.', '\\n', 'press', 'conference', ',', 'coach', 'praised', 'players', 'strategy', ',', 'dedication', ',', 'ability', 'adapt', 'match', 'progressed', '.', '\\n', 'highlighted', 'victory', 'strengthens', 'team', 'confidence', 'prepares', 'future', 'challenges', '.', '\\n', 'upcoming', 'match', 'important', ',', 'team', 'competing', 'spot', 'finals', '.', '\\n', 'Analysts', 'agree', 'team', 'continues', 'level', 'teamwork', 'discipline', ',', 'strong', 'chance', 'winning', 'entire', 'championship', '.', '\\n', 'end', ',', 'team', 'proved', 'success', 'individual', 'talent', 'unity', ',', 'effort', ',', 'shared', 'goal', 'winning', 'championship', '.', '\\n']\n",
            "['\\n', 'team', 'played', 'intense', 'match', 'night', ',', 'delivering', 'strongest', 'performances', 'season', '.', '\\n', 'match', ',', 'team', 'demonstrated', 'exceptional', 'teamwork', ',', 'discipline', ',', 'determination', '.', '\\n', 'coach', 'repeatedly', 'emphasized', 'important', 'teamwork', 'maintaining', 'control', 'difficult', 'moments', 'match', '.', '\\n', 'players', 'mentioned', 'team', 'trained', 'specifically', 'improve', 'teamwork', 'communication', ',', 'clearly', 'paid', '.', '\\n', 'Fans', 'celebrated', 'loudly', 'match', ',', 'recognizing', 'team', 'victory', 'crucial', 'improving', 'position', 'championship', '.', '\\n', 'press', 'conference', ',', 'coach', 'praised', 'players', 'strategy', ',', 'dedication', ',', 'ability', 'adapt', 'match', 'progressed', '.', '\\n', 'highlighted', 'victory', 'strengthens', 'team', 'confidence', 'prepares', 'future', 'challenges', '.', '\\n', 'upcoming', 'match', 'important', ',', 'team', 'competing', 'spot', 'finals', '.', '\\n', 'Analysts', 'agree', 'team', 'continues', 'level', 'teamwork', 'discipline', ',', 'strong', 'chance', 'winning', 'entire', 'championship', '.', '\\n', 'end', ',', 'team', 'proved', 'success', 'individual', 'talent', 'unity', ',', 'effort', ',', 'shared', 'goal', 'winning', 'championship', '.', '\\n']\n",
            "\n",
            "               → \n",
            "\n",
            "The             → the\n",
            "team            → team\n",
            "played          → play\n",
            "an              → an\n",
            "intense         → intense\n",
            "match           → match\n",
            "last            → last\n",
            "night           → night\n",
            ",               → ,\n",
            "delivering      → deliver\n",
            "one             → one\n",
            "of              → of\n",
            "their           → their\n",
            "strongest       → strong\n",
            "performances    → performance\n",
            "this            → this\n",
            "season          → season\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "Throughout      → throughout\n",
            "the             → the\n",
            "match           → match\n",
            ",               → ,\n",
            "the             → the\n",
            "team            → team\n",
            "demonstrated    → demonstrate\n",
            "exceptional     → exceptional\n",
            "teamwork        → teamwork\n",
            ",               → ,\n",
            "discipline      → discipline\n",
            ",               → ,\n",
            "and             → and\n",
            "determination   → determination\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "The             → the\n",
            "coach           → coach\n",
            "repeatedly      → repeatedly\n",
            "emphasized      → emphasize\n",
            "how             → how\n",
            "important       → important\n",
            "teamwork        → teamwork\n",
            "was             → be\n",
            "for             → for\n",
            "maintaining     → maintain\n",
            "control         → control\n",
            "during          → during\n",
            "the             → the\n",
            "most            → most\n",
            "difficult       → difficult\n",
            "moments         → moment\n",
            "of              → of\n",
            "the             → the\n",
            "match           → match\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "Several         → several\n",
            "players         → player\n",
            "mentioned       → mention\n",
            "that            → that\n",
            "the             → the\n",
            "team            → team\n",
            "had             → have\n",
            "trained         → train\n",
            "specifically    → specifically\n",
            "to              → to\n",
            "improve         → improve\n",
            "their           → their\n",
            "teamwork        → teamwork\n",
            "and             → and\n",
            "communication   → communication\n",
            ",               → ,\n",
            "which           → which\n",
            "clearly         → clearly\n",
            "paid            → pay\n",
            "off             → off\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "Fans            → fan\n",
            "celebrated      → celebrate\n",
            "loudly          → loudly\n",
            "after           → after\n",
            "the             → the\n",
            "match           → match\n",
            ",               → ,\n",
            "recognizing     → recognize\n",
            "that            → that\n",
            "the             → the\n",
            "team            → team\n",
            "’s              → ’s\n",
            "victory         → victory\n",
            "was             → be\n",
            "crucial         → crucial\n",
            "for             → for\n",
            "improving       → improve\n",
            "their           → their\n",
            "position        → position\n",
            "in              → in\n",
            "the             → the\n",
            "championship    → championship\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "During          → during\n",
            "the             → the\n",
            "press           → press\n",
            "conference      → conference\n",
            ",               → ,\n",
            "the             → the\n",
            "coach           → coach\n",
            "praised         → praise\n",
            "the             → the\n",
            "players         → player\n",
            "for             → for\n",
            "their           → their\n",
            "strategy        → strategy\n",
            ",               → ,\n",
            "dedication      → dedication\n",
            ",               → ,\n",
            "and             → and\n",
            "ability         → ability\n",
            "to              → to\n",
            "adapt           → adapt\n",
            "as              → as\n",
            "the             → the\n",
            "match           → match\n",
            "progressed      → progress\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "He              → he\n",
            "highlighted     → highlight\n",
            "that            → that\n",
            "every           → every\n",
            "victory         → victory\n",
            "strengthens     → strengthen\n",
            "the             → the\n",
            "team            → team\n",
            "’s              → ’s\n",
            "confidence      → confidence\n",
            "and             → and\n",
            "prepares        → prepare\n",
            "them            → they\n",
            "for             → for\n",
            "future          → future\n",
            "challenges      → challenge\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "The             → the\n",
            "upcoming        → upcoming\n",
            "match           → match\n",
            "is              → be\n",
            "even            → even\n",
            "more            → more\n",
            "important       → important\n",
            ",               → ,\n",
            "as              → as\n",
            "the             → the\n",
            "team            → team\n",
            "is              → be\n",
            "competing       → compete\n",
            "for             → for\n",
            "a               → a\n",
            "spot            → spot\n",
            "in              → in\n",
            "the             → the\n",
            "finals          → final\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "Analysts        → analyst\n",
            "agree           → agree\n",
            "that            → that\n",
            "if              → if\n",
            "the             → the\n",
            "team            → team\n",
            "continues       → continue\n",
            "to              → to\n",
            "show            → show\n",
            "this            → this\n",
            "level           → level\n",
            "of              → of\n",
            "teamwork        → teamwork\n",
            "and             → and\n",
            "discipline      → discipline\n",
            ",               → ,\n",
            "they            → they\n",
            "have            → have\n",
            "a               → a\n",
            "strong          → strong\n",
            "chance          → chance\n",
            "of              → of\n",
            "winning         → win\n",
            "the             → the\n",
            "entire          → entire\n",
            "championship    → championship\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "In              → in\n",
            "the             → the\n",
            "end             → end\n",
            ",               → ,\n",
            "the             → the\n",
            "team            → team\n",
            "proved          → prove\n",
            "that            → that\n",
            "success         → success\n",
            "is              → be\n",
            "not             → not\n",
            "just            → just\n",
            "about           → about\n",
            "individual      → individual\n",
            "talent          → talent\n",
            "but             → but\n",
            "about           → about\n",
            "unity           → unity\n",
            ",               → ,\n",
            "effort          → effort\n",
            ",               → ,\n",
            "and             → and\n",
            "the             → the\n",
            "shared          → share\n",
            "goal            → goal\n",
            "of              → of\n",
            "winning         → win\n",
            "the             → the\n",
            "championship    → championship\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "\n",
            "               → \n",
            "\n",
            "Modern          → modern\n",
            "technology      → technology\n",
            "is              → be\n",
            "evolving        → evolve\n",
            "rapidly         → rapidly\n",
            ",               → ,\n",
            "shaping         → shape\n",
            "the             → the\n",
            "way             → way\n",
            "people          → people\n",
            "work            → work\n",
            ",               → ,\n",
            "communicate     → communicate\n",
            ",               → ,\n",
            "and             → and\n",
            "solve           → solve\n",
            "complex         → complex\n",
            "problems        → problem\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "New             → new\n",
            "devices         → device\n",
            "and             → and\n",
            "software        → software\n",
            "are             → be\n",
            "developed       → develop\n",
            "every           → every\n",
            "year            → year\n",
            ",               → ,\n",
            "pushing         → push\n",
            "the             → the\n",
            "boundaries      → boundary\n",
            "of              → of\n",
            "what            → what\n",
            "modern          → modern\n",
            "technology      → technology\n",
            "can             → can\n",
            "achieve         → achieve\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "Researchers     → researcher\n",
            "are             → be\n",
            "focusing        → focus\n",
            "heavily         → heavily\n",
            "on              → on\n",
            "artificial      → artificial\n",
            "intelligence    → intelligence\n",
            ",               → ,\n",
            "automation      → automation\n",
            ",               → ,\n",
            "and             → and\n",
            "advanced        → advanced\n",
            "data            → datum\n",
            "processing      → processing\n",
            "to              → to\n",
            "create          → create\n",
            "smarter         → smart\n",
            "and             → and\n",
            "more            → more\n",
            "powerful        → powerful\n",
            "systems         → system\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "These           → these\n",
            "innovations     → innovation\n",
            "enable          → enable\n",
            "companies       → company\n",
            "to              → to\n",
            "build           → build\n",
            "faster          → fast\n",
            "devices         → device\n",
            ",               → ,\n",
            "more            → more\n",
            "secure          → secure\n",
            "software        → software\n",
            ",               → ,\n",
            "and             → and\n",
            "highly          → highly\n",
            "efficient       → efficient\n",
            "solutions       → solution\n",
            "for             → for\n",
            "everyday        → everyday\n",
            "use             → use\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "Experts         → expert\n",
            "believe         → believe\n",
            "that            → that\n",
            "artificial      → artificial\n",
            "intelligence    → intelligence\n",
            "will            → will\n",
            "continue        → continue\n",
            "to              → to\n",
            "transform       → transform\n",
            "technology      → technology\n",
            "by              → by\n",
            "improving       → improve\n",
            "decision        → decision\n",
            "-               → -\n",
            "making          → making\n",
            ",               → ,\n",
            "optimizing      → optimize\n",
            "workflows       → workflow\n",
            ",               → ,\n",
            "and             → and\n",
            "predicting      → predict\n",
            "user            → user\n",
            "needs           → need\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "Many            → many\n",
            "companies       → company\n",
            "are             → be\n",
            "investing       → invest\n",
            "in              → in\n",
            "automation      → automation\n",
            "technologies    → technology\n",
            "to              → to\n",
            "reduce          → reduce\n",
            "costs           → cost\n",
            ",               → ,\n",
            "increase        → increase\n",
            "productivity    → productivity\n",
            ",               → ,\n",
            "and             → and\n",
            "eliminate       → eliminate\n",
            "repetitive      → repetitive\n",
            "tasks           → task\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "At              → at\n",
            "the             → the\n",
            "same            → same\n",
            "time            → time\n",
            ",               → ,\n",
            "advancements    → advancement\n",
            "in              → in\n",
            "data            → data\n",
            "processing      → processing\n",
            "make            → make\n",
            "it              → it\n",
            "possible        → possible\n",
            "to              → to\n",
            "analyze         → analyze\n",
            "enormous        → enormous\n",
            "datasets        → dataset\n",
            "and             → and\n",
            "identify        → identify\n",
            "patterns        → pattern\n",
            "that            → that\n",
            "were            → be\n",
            "previously      → previously\n",
            "impossible      → impossible\n",
            "to              → to\n",
            "detect          → detect\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "This            → this\n",
            "combination     → combination\n",
            "of              → of\n",
            "artificial      → artificial\n",
            "intelligence    → intelligence\n",
            ",               → ,\n",
            "automation      → automation\n",
            ",               → ,\n",
            "and             → and\n",
            "data            → datum\n",
            "processing      → processing\n",
            "is              → be\n",
            "driving         → drive\n",
            "a               → a\n",
            "new             → new\n",
            "era             → era\n",
            "of              → of\n",
            "modern          → modern\n",
            "technology      → technology\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "If              → if\n",
            "current         → current\n",
            "trends          → trend\n",
            "continue        → continue\n",
            ",               → ,\n",
            "technology      → technology\n",
            "will            → will\n",
            "become          → become\n",
            "even            → even\n",
            "more            → more\n",
            "integrated      → integrate\n",
            "into            → into\n",
            "daily           → daily\n",
            "life            → life\n",
            ",               → ,\n",
            "offering        → offer\n",
            "smarter         → smart\n",
            "devices         → device\n",
            ",               → ,\n",
            "adaptive        → adaptive\n",
            "software        → software\n",
            ",               → ,\n",
            "and             → and\n",
            "personalized    → personalized\n",
            "solutions       → solution\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "Researchers     → researcher\n",
            "conclude        → conclude\n",
            "that            → that\n",
            "the             → the\n",
            "future          → future\n",
            "of              → of\n",
            "modern          → modern\n",
            "technology      → technology\n",
            "depends         → depend\n",
            "on              → on\n",
            "continuous      → continuous\n",
            "innovation      → innovation\n",
            ",               → ,\n",
            "reliable        → reliable\n",
            "data            → datum\n",
            "processing      → processing\n",
            ",               → ,\n",
            "and             → and\n",
            "the             → the\n",
            "responsible     → responsible\n",
            "development     → development\n",
            "of              → of\n",
            "artificial      → artificial\n",
            "intelligence    → intelligence\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "\n",
            "               → SPACE  (_SP)\n",
            "The             → DET    (DT)\n",
            "team            → NOUN   (NN)\n",
            "played          → VERB   (VBD)\n",
            "an              → DET    (DT)\n",
            "intense         → ADJ    (JJ)\n",
            "match           → NOUN   (NN)\n",
            "last            → ADJ    (JJ)\n",
            "night           → NOUN   (NN)\n",
            ",               → PUNCT  (,)\n",
            "delivering      → VERB   (VBG)\n",
            "one             → NUM    (CD)\n",
            "of              → ADP    (IN)\n",
            "their           → PRON   (PRP$)\n",
            "strongest       → ADJ    (JJS)\n",
            "performances    → NOUN   (NNS)\n",
            "this            → DET    (DT)\n",
            "season          → NOUN   (NN)\n",
            ".               → PUNCT  (.)\n",
            "\n",
            "               → SPACE  (_SP)\n",
            "Throughout      → ADP    (IN)\n",
            "the             → DET    (DT)\n",
            "match           → NOUN   (NN)\n",
            ",               → PUNCT  (,)\n",
            "the             → DET    (DT)\n",
            "team            → NOUN   (NN)\n",
            "demonstrated    → VERB   (VBD)\n",
            "exceptional     → ADJ    (JJ)\n",
            "teamwork        → NOUN   (NN)\n",
            ",               → PUNCT  (,)\n",
            "discipline      → NOUN   (NN)\n",
            ",               → PUNCT  (,)\n",
            "and             → CCONJ  (CC)\n",
            "determination   → NOUN   (NN)\n",
            ".               → PUNCT  (.)\n",
            "\n",
            "               → SPACE  (_SP)\n",
            "The             → DET    (DT)\n",
            "coach           → NOUN   (NN)\n",
            "repeatedly      → ADV    (RB)\n",
            "emphasized      → VERB   (VBD)\n",
            "how             → SCONJ  (WRB)\n",
            "important       → ADJ    (JJ)\n",
            "teamwork        → NOUN   (NN)\n",
            "was             → AUX    (VBD)\n",
            "for             → ADP    (IN)\n",
            "maintaining     → VERB   (VBG)\n",
            "control         → NOUN   (NN)\n",
            "during          → ADP    (IN)\n",
            "the             → DET    (DT)\n",
            "most            → ADV    (RBS)\n",
            "difficult       → ADJ    (JJ)\n",
            "moments         → NOUN   (NNS)\n",
            "of              → ADP    (IN)\n",
            "the             → DET    (DT)\n",
            "match           → NOUN   (NN)\n",
            ".               → PUNCT  (.)\n",
            "\n",
            "               → SPACE  (_SP)\n",
            "Several         → ADJ    (JJ)\n",
            "players         → NOUN   (NNS)\n",
            "mentioned       → VERB   (VBD)\n",
            "that            → SCONJ  (IN)\n",
            "the             → DET    (DT)\n",
            "team            → NOUN   (NN)\n",
            "had             → AUX    (VBD)\n",
            "trained         → VERB   (VBN)\n",
            "specifically    → ADV    (RB)\n",
            "to              → PART   (TO)\n",
            "improve         → VERB   (VB)\n",
            "their           → PRON   (PRP$)\n",
            "teamwork        → NOUN   (NN)\n",
            "and             → CCONJ  (CC)\n",
            "communication   → NOUN   (NN)\n",
            ",               → PUNCT  (,)\n",
            "which           → PRON   (WDT)\n",
            "clearly         → ADV    (RB)\n",
            "paid            → VERB   (VBD)\n",
            "off             → ADP    (RP)\n",
            ".               → PUNCT  (.)\n",
            "\n",
            "               → SPACE  (_SP)\n",
            "Fans            → NOUN   (NNS)\n",
            "celebrated      → VERB   (VBD)\n",
            "loudly          → ADV    (RB)\n",
            "after           → ADP    (IN)\n",
            "the             → DET    (DT)\n",
            "match           → NOUN   (NN)\n",
            ",               → PUNCT  (,)\n",
            "recognizing     → VERB   (VBG)\n",
            "that            → SCONJ  (IN)\n",
            "the             → DET    (DT)\n",
            "team            → NOUN   (NN)\n",
            "’s              → PART   (POS)\n",
            "victory         → NOUN   (NN)\n",
            "was             → AUX    (VBD)\n",
            "crucial         → ADJ    (JJ)\n",
            "for             → ADP    (IN)\n",
            "improving       → VERB   (VBG)\n",
            "their           → PRON   (PRP$)\n",
            "position        → NOUN   (NN)\n",
            "in              → ADP    (IN)\n",
            "the             → DET    (DT)\n",
            "championship    → NOUN   (NN)\n",
            ".               → PUNCT  (.)\n",
            "\n",
            "               → SPACE  (_SP)\n",
            "During          → ADP    (IN)\n",
            "the             → DET    (DT)\n",
            "press           → NOUN   (NN)\n",
            "conference      → NOUN   (NN)\n",
            ",               → PUNCT  (,)\n",
            "the             → DET    (DT)\n",
            "coach           → NOUN   (NN)\n",
            "praised         → VERB   (VBD)\n",
            "the             → DET    (DT)\n",
            "players         → NOUN   (NNS)\n",
            "for             → ADP    (IN)\n",
            "their           → PRON   (PRP$)\n",
            "strategy        → NOUN   (NN)\n",
            ",               → PUNCT  (,)\n",
            "dedication      → NOUN   (NN)\n",
            ",               → PUNCT  (,)\n",
            "and             → CCONJ  (CC)\n",
            "ability         → NOUN   (NN)\n",
            "to              → PART   (TO)\n",
            "adapt           → VERB   (VB)\n",
            "as              → SCONJ  (IN)\n",
            "the             → DET    (DT)\n",
            "match           → NOUN   (NN)\n",
            "progressed      → VERB   (VBD)\n",
            ".               → PUNCT  (.)\n",
            "\n",
            "               → SPACE  (_SP)\n",
            "He              → PRON   (PRP)\n",
            "highlighted     → VERB   (VBD)\n",
            "that            → SCONJ  (IN)\n",
            "every           → DET    (DT)\n",
            "victory         → NOUN   (NN)\n",
            "strengthens     → VERB   (VBZ)\n",
            "the             → DET    (DT)\n",
            "team            → NOUN   (NN)\n",
            "’s              → PART   (POS)\n",
            "confidence      → NOUN   (NN)\n",
            "and             → CCONJ  (CC)\n",
            "prepares        → VERB   (VBZ)\n",
            "them            → PRON   (PRP)\n",
            "for             → ADP    (IN)\n",
            "future          → ADJ    (JJ)\n",
            "challenges      → NOUN   (NNS)\n",
            ".               → PUNCT  (.)\n",
            "\n",
            "               → SPACE  (_SP)\n",
            "The             → DET    (DT)\n",
            "upcoming        → ADJ    (JJ)\n",
            "match           → NOUN   (NN)\n",
            "is              → AUX    (VBZ)\n",
            "even            → ADV    (RB)\n",
            "more            → ADV    (RBR)\n",
            "important       → ADJ    (JJ)\n",
            ",               → PUNCT  (,)\n",
            "as              → SCONJ  (IN)\n",
            "the             → DET    (DT)\n",
            "team            → NOUN   (NN)\n",
            "is              → AUX    (VBZ)\n",
            "competing       → VERB   (VBG)\n",
            "for             → ADP    (IN)\n",
            "a               → DET    (DT)\n",
            "spot            → NOUN   (NN)\n",
            "in              → ADP    (IN)\n",
            "the             → DET    (DT)\n",
            "finals          → NOUN   (NNS)\n",
            ".               → PUNCT  (.)\n",
            "\n",
            "               → SPACE  (_SP)\n",
            "Analysts        → NOUN   (NNS)\n",
            "agree           → VERB   (VBP)\n",
            "that            → SCONJ  (IN)\n",
            "if              → SCONJ  (IN)\n",
            "the             → DET    (DT)\n",
            "team            → NOUN   (NN)\n",
            "continues       → VERB   (VBZ)\n",
            "to              → PART   (TO)\n",
            "show            → VERB   (VB)\n",
            "this            → DET    (DT)\n",
            "level           → NOUN   (NN)\n",
            "of              → ADP    (IN)\n",
            "teamwork        → NOUN   (NN)\n",
            "and             → CCONJ  (CC)\n",
            "discipline      → NOUN   (NN)\n",
            ",               → PUNCT  (,)\n",
            "they            → PRON   (PRP)\n",
            "have            → VERB   (VBP)\n",
            "a               → DET    (DT)\n",
            "strong          → ADJ    (JJ)\n",
            "chance          → NOUN   (NN)\n",
            "of              → ADP    (IN)\n",
            "winning         → VERB   (VBG)\n",
            "the             → DET    (DT)\n",
            "entire          → ADJ    (JJ)\n",
            "championship    → NOUN   (NN)\n",
            ".               → PUNCT  (.)\n",
            "\n",
            "               → SPACE  (_SP)\n",
            "In              → ADP    (IN)\n",
            "the             → DET    (DT)\n",
            "end             → NOUN   (NN)\n",
            ",               → PUNCT  (,)\n",
            "the             → DET    (DT)\n",
            "team            → NOUN   (NN)\n",
            "proved          → VERB   (VBD)\n",
            "that            → SCONJ  (IN)\n",
            "success         → NOUN   (NN)\n",
            "is              → AUX    (VBZ)\n",
            "not             → PART   (RB)\n",
            "just            → ADV    (RB)\n",
            "about           → ADP    (IN)\n",
            "individual      → ADJ    (JJ)\n",
            "talent          → NOUN   (NN)\n",
            "but             → CCONJ  (CC)\n",
            "about           → ADP    (IN)\n",
            "unity           → NOUN   (NN)\n",
            ",               → PUNCT  (,)\n",
            "effort          → NOUN   (NN)\n",
            ",               → PUNCT  (,)\n",
            "and             → CCONJ  (CC)\n",
            "the             → DET    (DT)\n",
            "shared          → VERB   (VBN)\n",
            "goal            → NOUN   (NN)\n",
            "of              → ADP    (IN)\n",
            "winning         → VERB   (VBG)\n",
            "the             → DET    (DT)\n",
            "championship    → NOUN   (NN)\n",
            ".               → PUNCT  (.)\n",
            "\n",
            "               → SPACE  (_SP)\n",
            "\n",
            "               → SPACE  (_SP)\n",
            "Modern          → ADJ    (JJ)\n",
            "technology      → NOUN   (NN)\n",
            "is              → AUX    (VBZ)\n",
            "evolving        → VERB   (VBG)\n",
            "rapidly         → ADV    (RB)\n",
            ",               → PUNCT  (,)\n",
            "shaping         → VERB   (VBG)\n",
            "the             → DET    (DT)\n",
            "way             → NOUN   (NN)\n",
            "people          → NOUN   (NNS)\n",
            "work            → VERB   (VBP)\n",
            ",               → PUNCT  (,)\n",
            "communicate     → VERB   (VBP)\n",
            ",               → PUNCT  (,)\n",
            "and             → CCONJ  (CC)\n",
            "solve           → VERB   (VB)\n",
            "complex         → ADJ    (JJ)\n",
            "problems        → NOUN   (NNS)\n",
            ".               → PUNCT  (.)\n",
            "\n",
            "               → SPACE  (_SP)\n",
            "New             → ADJ    (JJ)\n",
            "devices         → NOUN   (NNS)\n",
            "and             → CCONJ  (CC)\n",
            "software        → NOUN   (NN)\n",
            "are             → AUX    (VBP)\n",
            "developed       → VERB   (VBN)\n",
            "every           → DET    (DT)\n",
            "year            → NOUN   (NN)\n",
            ",               → PUNCT  (,)\n",
            "pushing         → VERB   (VBG)\n",
            "the             → DET    (DT)\n",
            "boundaries      → NOUN   (NNS)\n",
            "of              → ADP    (IN)\n",
            "what            → PRON   (WP)\n",
            "modern          → ADJ    (JJ)\n",
            "technology      → NOUN   (NN)\n",
            "can             → AUX    (MD)\n",
            "achieve         → VERB   (VB)\n",
            ".               → PUNCT  (.)\n",
            "\n",
            "               → SPACE  (_SP)\n",
            "Researchers     → NOUN   (NNS)\n",
            "are             → AUX    (VBP)\n",
            "focusing        → VERB   (VBG)\n",
            "heavily         → ADV    (RB)\n",
            "on              → ADP    (IN)\n",
            "artificial      → ADJ    (JJ)\n",
            "intelligence    → NOUN   (NN)\n",
            ",               → PUNCT  (,)\n",
            "automation      → NOUN   (NN)\n",
            ",               → PUNCT  (,)\n",
            "and             → CCONJ  (CC)\n",
            "advanced        → ADJ    (JJ)\n",
            "data            → NOUN   (NNS)\n",
            "processing      → NOUN   (NN)\n",
            "to              → PART   (TO)\n",
            "create          → VERB   (VB)\n",
            "smarter         → ADJ    (JJR)\n",
            "and             → CCONJ  (CC)\n",
            "more            → ADV    (RBR)\n",
            "powerful        → ADJ    (JJ)\n",
            "systems         → NOUN   (NNS)\n",
            ".               → PUNCT  (.)\n",
            "\n",
            "               → SPACE  (_SP)\n",
            "These           → DET    (DT)\n",
            "innovations     → NOUN   (NNS)\n",
            "enable          → VERB   (VBP)\n",
            "companies       → NOUN   (NNS)\n",
            "to              → PART   (TO)\n",
            "build           → VERB   (VB)\n",
            "faster          → ADJ    (JJR)\n",
            "devices         → NOUN   (NNS)\n",
            ",               → PUNCT  (,)\n",
            "more            → ADV    (RBR)\n",
            "secure          → ADJ    (JJ)\n",
            "software        → NOUN   (NN)\n",
            ",               → PUNCT  (,)\n",
            "and             → CCONJ  (CC)\n",
            "highly          → ADV    (RB)\n",
            "efficient       → ADJ    (JJ)\n",
            "solutions       → NOUN   (NNS)\n",
            "for             → ADP    (IN)\n",
            "everyday        → ADJ    (JJ)\n",
            "use             → NOUN   (NN)\n",
            ".               → PUNCT  (.)\n",
            "\n",
            "               → SPACE  (_SP)\n",
            "Experts         → NOUN   (NNS)\n",
            "believe         → VERB   (VBP)\n",
            "that            → SCONJ  (IN)\n",
            "artificial      → ADJ    (JJ)\n",
            "intelligence    → NOUN   (NN)\n",
            "will            → AUX    (MD)\n",
            "continue        → VERB   (VB)\n",
            "to              → PART   (TO)\n",
            "transform       → VERB   (VB)\n",
            "technology      → NOUN   (NN)\n",
            "by              → ADP    (IN)\n",
            "improving       → VERB   (VBG)\n",
            "decision        → NOUN   (NN)\n",
            "-               → PUNCT  (HYPH)\n",
            "making          → NOUN   (NN)\n",
            ",               → PUNCT  (,)\n",
            "optimizing      → VERB   (VBG)\n",
            "workflows       → NOUN   (NNS)\n",
            ",               → PUNCT  (,)\n",
            "and             → CCONJ  (CC)\n",
            "predicting      → VERB   (VBG)\n",
            "user            → NOUN   (NN)\n",
            "needs           → NOUN   (NNS)\n",
            ".               → PUNCT  (.)\n",
            "\n",
            "               → SPACE  (_SP)\n",
            "Many            → ADJ    (JJ)\n",
            "companies       → NOUN   (NNS)\n",
            "are             → AUX    (VBP)\n",
            "investing       → VERB   (VBG)\n",
            "in              → ADP    (IN)\n",
            "automation      → NOUN   (NN)\n",
            "technologies    → NOUN   (NNS)\n",
            "to              → PART   (TO)\n",
            "reduce          → VERB   (VB)\n",
            "costs           → NOUN   (NNS)\n",
            ",               → PUNCT  (,)\n",
            "increase        → VERB   (VB)\n",
            "productivity    → NOUN   (NN)\n",
            ",               → PUNCT  (,)\n",
            "and             → CCONJ  (CC)\n",
            "eliminate       → VERB   (VB)\n",
            "repetitive      → ADJ    (JJ)\n",
            "tasks           → NOUN   (NNS)\n",
            ".               → PUNCT  (.)\n",
            "\n",
            "               → SPACE  (_SP)\n",
            "At              → ADP    (IN)\n",
            "the             → DET    (DT)\n",
            "same            → ADJ    (JJ)\n",
            "time            → NOUN   (NN)\n",
            ",               → PUNCT  (,)\n",
            "advancements    → NOUN   (NNS)\n",
            "in              → ADP    (IN)\n",
            "data            → NOUN   (NN)\n",
            "processing      → NOUN   (NN)\n",
            "make            → VERB   (VBP)\n",
            "it              → PRON   (PRP)\n",
            "possible        → ADJ    (JJ)\n",
            "to              → PART   (TO)\n",
            "analyze         → VERB   (VB)\n",
            "enormous        → ADJ    (JJ)\n",
            "datasets        → NOUN   (NNS)\n",
            "and             → CCONJ  (CC)\n",
            "identify        → VERB   (VB)\n",
            "patterns        → NOUN   (NNS)\n",
            "that            → PRON   (WDT)\n",
            "were            → AUX    (VBD)\n",
            "previously      → ADV    (RB)\n",
            "impossible      → ADJ    (JJ)\n",
            "to              → PART   (TO)\n",
            "detect          → VERB   (VB)\n",
            ".               → PUNCT  (.)\n",
            "\n",
            "               → SPACE  (_SP)\n",
            "This            → DET    (DT)\n",
            "combination     → NOUN   (NN)\n",
            "of              → ADP    (IN)\n",
            "artificial      → ADJ    (JJ)\n",
            "intelligence    → NOUN   (NN)\n",
            ",               → PUNCT  (,)\n",
            "automation      → NOUN   (NN)\n",
            ",               → PUNCT  (,)\n",
            "and             → CCONJ  (CC)\n",
            "data            → NOUN   (NNS)\n",
            "processing      → NOUN   (NN)\n",
            "is              → AUX    (VBZ)\n",
            "driving         → VERB   (VBG)\n",
            "a               → DET    (DT)\n",
            "new             → ADJ    (JJ)\n",
            "era             → NOUN   (NN)\n",
            "of              → ADP    (IN)\n",
            "modern          → ADJ    (JJ)\n",
            "technology      → NOUN   (NN)\n",
            ".               → PUNCT  (.)\n",
            "\n",
            "               → SPACE  (_SP)\n",
            "If              → SCONJ  (IN)\n",
            "current         → ADJ    (JJ)\n",
            "trends          → NOUN   (NNS)\n",
            "continue        → VERB   (VBP)\n",
            ",               → PUNCT  (,)\n",
            "technology      → NOUN   (NN)\n",
            "will            → AUX    (MD)\n",
            "become          → VERB   (VB)\n",
            "even            → ADV    (RB)\n",
            "more            → ADV    (RBR)\n",
            "integrated      → VERB   (VBN)\n",
            "into            → ADP    (IN)\n",
            "daily           → ADJ    (JJ)\n",
            "life            → NOUN   (NN)\n",
            ",               → PUNCT  (,)\n",
            "offering        → VERB   (VBG)\n",
            "smarter         → ADJ    (JJR)\n",
            "devices         → NOUN   (NNS)\n",
            ",               → PUNCT  (,)\n",
            "adaptive        → ADJ    (JJ)\n",
            "software        → NOUN   (NN)\n",
            ",               → PUNCT  (,)\n",
            "and             → CCONJ  (CC)\n",
            "personalized    → ADJ    (JJ)\n",
            "solutions       → NOUN   (NNS)\n",
            ".               → PUNCT  (.)\n",
            "\n",
            "               → SPACE  (_SP)\n",
            "Researchers     → NOUN   (NNS)\n",
            "conclude        → VERB   (VBP)\n",
            "that            → SCONJ  (IN)\n",
            "the             → DET    (DT)\n",
            "future          → NOUN   (NN)\n",
            "of              → ADP    (IN)\n",
            "modern          → ADJ    (JJ)\n",
            "technology      → NOUN   (NN)\n",
            "depends         → VERB   (VBZ)\n",
            "on              → ADP    (IN)\n",
            "continuous      → ADJ    (JJ)\n",
            "innovation      → NOUN   (NN)\n",
            ",               → PUNCT  (,)\n",
            "reliable        → ADJ    (JJ)\n",
            "data            → NOUN   (NNS)\n",
            "processing      → NOUN   (NN)\n",
            ",               → PUNCT  (,)\n",
            "and             → CCONJ  (CC)\n",
            "the             → DET    (DT)\n",
            "responsible     → ADJ    (JJ)\n",
            "development     → NOUN   (NN)\n",
            "of              → ADP    (IN)\n",
            "artificial      → ADJ    (JJ)\n",
            "intelligence    → NOUN   (NN)\n",
            ".               → PUNCT  (.)\n",
            "\n",
            "               → SPACE  (_SP)\n",
            "Sport NOUNS:\n",
            "['team', 'match', 'night', 'performance', 'season', 'match', 'team', 'teamwork', 'discipline', 'determination', 'coach', 'teamwork', 'control', 'moment', 'match', 'player', 'team', 'teamwork', 'communication', 'fan', 'match', 'team', 'victory', 'position', 'championship', 'press', 'conference', 'coach', 'player', 'strategy', 'dedication', 'ability', 'match', 'victory', 'team', 'confidence', 'challenge', 'match', 'team', 'spot', 'final', 'analyst', 'team', 'level', 'teamwork', 'discipline', 'chance', 'championship', 'end', 'team', 'success', 'talent', 'unity', 'effort', 'goal', 'championship']\n",
            "Tech NOUNS:\n",
            "['technology', 'way', 'people', 'problem', 'device', 'software', 'year', 'boundary', 'technology', 'researcher', 'intelligence', 'automation', 'datum', 'processing', 'system', 'innovation', 'company', 'device', 'software', 'solution', 'use', 'expert', 'intelligence', 'technology', 'decision', 'making', 'workflow', 'user', 'need', 'company', 'automation', 'technology', 'cost', 'productivity', 'task', 'time', 'advancement', 'data', 'processing', 'dataset', 'pattern', 'combination', 'intelligence', 'automation', 'datum', 'processing', 'era', 'technology', 'trend', 'technology', 'life', 'device', 'software', 'solution', 'researcher', 'future', 'technology', 'innovation', 'datum', 'processing', 'development', 'intelligence']\n",
            "sport:\n",
            "Counter({'team': 8, 'match': 6, 'teamwork': 4, 'championship': 3, 'discipline': 2, 'coach': 2, 'player': 2, 'victory': 2, 'night': 1, 'performance': 1, 'season': 1, 'determination': 1, 'control': 1, 'moment': 1, 'communication': 1, 'fan': 1, 'position': 1, 'press': 1, 'conference': 1, 'strategy': 1, 'dedication': 1, 'ability': 1, 'confidence': 1, 'challenge': 1, 'spot': 1, 'final': 1, 'analyst': 1, 'level': 1, 'chance': 1, 'end': 1, 'success': 1, 'talent': 1, 'unity': 1, 'effort': 1, 'goal': 1})\n",
            "tech:\n",
            "Counter({'technology': 7, 'intelligence': 4, 'processing': 4, 'device': 3, 'software': 3, 'automation': 3, 'datum': 3, 'researcher': 2, 'innovation': 2, 'company': 2, 'solution': 2, 'way': 1, 'people': 1, 'problem': 1, 'year': 1, 'boundary': 1, 'system': 1, 'use': 1, 'expert': 1, 'decision': 1, 'making': 1, 'workflow': 1, 'user': 1, 'need': 1, 'cost': 1, 'productivity': 1, 'task': 1, 'time': 1, 'advancement': 1, 'data': 1, 'dataset': 1, 'pattern': 1, 'combination': 1, 'era': 1, 'trend': 1, 'life': 1, 'future': 1, 'development': 1})\n",
            "top 5 sport:\n",
            "[('team', 8), ('match', 6), ('teamwork', 4), ('championship', 3), ('discipline', 2)]\n",
            "top 5 tech:\n",
            "[('technology', 7), ('intelligence', 4), ('processing', 4), ('device', 3), ('software', 3)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "top 5 sport:\n",
        "[('team', 8), ('match', 6), ('teamwork', 4), ('championship', 3), ('discipline', 2)]\n",
        "top 5 tech:\n",
        "[('technology', 7), ('intelligence', 4), ('processing', 4), ('device', 3), ('software', 3)]\n",
        "\n",
        "Bazirano na tome bi zaključio da je tekst 1 o nekom sportu, možda konkretno nogometu, a da je tekst 2 o nečemu u području tehnologije, možda konkretno AI ili machine learning.\n"
      ],
      "metadata": {
        "id": "Eyz5bTdMO6iV"
      },
      "id": "Eyz5bTdMO6iV"
    },
    {
      "cell_type": "markdown",
      "id": "8c585b56",
      "metadata": {
        "id": "8c585b56"
      },
      "source": [
        "## Zadatak 2: Analiza tonova (pozitivno vs. negativno)\n",
        "\n",
        "**Opis:**  \n",
        "Zadatak je provesti osnovnu analizu sentimenta.  \n",
        "Potrebno je obraditi nekoliko kratkih recenzija (npr. o filmovima, proizvodima, restoranima) i odrediti jesu li one pozitivne ili negativne.\n",
        "\n",
        "**Cilj:**  \n",
        "Pokazati kako se osnovni NLP alati mogu koristiti za analizu osjećaja u tekstu.\n",
        "\n",
        "**Upute:**  \n",
        "1. Pripremi popise riječi:  \n",
        "   - pozitivne: `[\"good\", \"great\", \"excellent\", \"amazing\", \"nice\", \"wonderful\"]`  \n",
        "   - negativne: `[\"bad\", \"poor\", \"terrible\", \"boring\", \"awful\", \"disappointing\"]`  \n",
        "2. Za svaku recenziju:  \n",
        "   - očisti tekst (ukloni stopwords, lematiziraj),  \n",
        "   - prebroji koliko pozitivnih i negativnih riječi sadrži.  \n",
        "3. Na temelju rezultata zaključi ton svake recenzije.  \n",
        "4. (Opcionalno) Prikaži rezultate u tablici ili grafu."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review1=\"It's a more concentrated and slightly simpler game than its brilliant second instalment, which really expanded every part and is better in my opinion. But if you scale it all down, it's still the same concept. You're treated to fantastic puzzles and a really nice facelift that makes it definitely worth experiencing. Even if it was then followed by something more grand and even better.\"\n",
        "review2=\"Where Winds Meet is over-ambitious, messy, opaque, and inconsistent. It has too many gears that don’t mesh, a lot that’s poorly explained, and it refuses to give the player a moment of unproductive time, even at the cost of coherence and comprehensibility. For all that, Where Winds Meet is a lot of fun. It often looks incredible and the world is certainly filled with content, whether for a single player or in a group. Even without touching the cash shop, Where Winds Meet provides a huge amount of free game play. Right now, Where Winds Meet is a little shy of greatness, but with some technical improvements and time it could get there.\"\n",
        "review3=\"Park Chan-wook’s Oldboy may frequently shock and disgust you, but you’ll find yourself unable to look away from the excellent filmmaking on display.\"\n",
        "\n",
        "positive = [\n",
        "    \"good\", \"great\", \"excellent\", \"amazing\", \"nice\", \"wonderful\", \"beautiful\",\n",
        "    \"fantastic\", \"incredible\", \"superb\", \"outstanding\", \"top-notch\", \"impressive\",\n",
        "    \"remarkable\", \"delightful\", \"satisfying\", \"pleasant\", \"charming\", \"engaging\",\n",
        "    \"marvelous\", \"fabulous\", \"stellar\", \"exceptional\", \"classy\", \"joyful\", \"refreshing\"\n",
        "]\n",
        "negative = [\n",
        "    \"bad\", \"poor\", \"terrible\", \"boring\", \"awful\", \"disappointing\", \"tragic\", \"disgust\",\n",
        "    \"horrible\", \"lousy\", \"unpleasant\", \"dismal\", \"shocking\", \"unbearable\", \"lackluster\",\n",
        "    \"inferior\", \"subpar\", \"regrettable\", \"unimpressive\", \"tedious\", \"mediocre\", \"unworthy\",\n",
        "    \"underwhelming\", \"frustrating\", \"disastrous\", \"unacceptable\", \"deplorable\", \"cringeworthy\"\n",
        "]\n",
        "\n",
        "\n",
        "reviews = [review1,review2,review3]\n",
        "\n"
      ],
      "metadata": {
        "id": "CLD-FeZJRNSy"
      },
      "id": "CLD-FeZJRNSy",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for review in reviews:\n",
        "  reviewTokens = []\n",
        "  myText = review\n",
        "  print(\"review text: \", myText)\n",
        "  doc = nlp(myText)\n",
        "  filtered_spacy = [token.text for token in doc if not token.is_stop]\n",
        "  print(\"lematization:\")\n",
        "  for token in doc:\n",
        "    print(f'{token.text:15} → {token.lemma_}')\n",
        "    reviewTokens.append(token.lemma_)\n",
        "\n",
        "  positive_count = 0\n",
        "  negative_count = 0\n",
        "\n",
        "  for word in reviewTokens:\n",
        "    if(word in positive):\n",
        "      positive_count+=1\n",
        "      print(\"added positive, for word:\", word)\n",
        "\n",
        "    if(word in negative):\n",
        "      negative_count+=1\n",
        "      print(\"added negative, for word:\", word)\n",
        "\n",
        "  print(\"reviewTokens:\")\n",
        "  print(reviewTokens)\n",
        "  print(\"positive, negative\", positive_count,negative_count)\n",
        "  print(\"--------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVf9yUB0TrYF",
        "outputId": "cb78e6df-46b4-4cbd-85f5-42d5cfffdbd1"
      },
      "id": "GVf9yUB0TrYF",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "review text:  It's a more concentrated and slightly simpler game than its brilliant second instalment, which really expanded every part and is better in my opinion. But if you scale it all down, it's still the same concept. You're treated to fantastic puzzles and a really nice facelift that makes it definitely worth experiencing. Even if it was then followed by something more grand and even better.\n",
            "lematization:\n",
            "It              → it\n",
            "'s              → be\n",
            "a               → a\n",
            "more            → more\n",
            "concentrated    → concentrated\n",
            "and             → and\n",
            "slightly        → slightly\n",
            "simpler         → simple\n",
            "game            → game\n",
            "than            → than\n",
            "its             → its\n",
            "brilliant       → brilliant\n",
            "second          → second\n",
            "instalment      → instalment\n",
            ",               → ,\n",
            "which           → which\n",
            "really          → really\n",
            "expanded        → expand\n",
            "every           → every\n",
            "part            → part\n",
            "and             → and\n",
            "is              → be\n",
            "better          → well\n",
            "in              → in\n",
            "my              → my\n",
            "opinion         → opinion\n",
            ".               → .\n",
            "But             → but\n",
            "if              → if\n",
            "you             → you\n",
            "scale           → scale\n",
            "it              → it\n",
            "all             → all\n",
            "down            → down\n",
            ",               → ,\n",
            "it              → it\n",
            "'s              → be\n",
            "still           → still\n",
            "the             → the\n",
            "same            → same\n",
            "concept         → concept\n",
            ".               → .\n",
            "You             → you\n",
            "'re             → be\n",
            "treated         → treat\n",
            "to              → to\n",
            "fantastic       → fantastic\n",
            "puzzles         → puzzle\n",
            "and             → and\n",
            "a               → a\n",
            "really          → really\n",
            "nice            → nice\n",
            "facelift        → facelift\n",
            "that            → that\n",
            "makes           → make\n",
            "it              → it\n",
            "definitely      → definitely\n",
            "worth           → worth\n",
            "experiencing    → experience\n",
            ".               → .\n",
            "Even            → even\n",
            "if              → if\n",
            "it              → it\n",
            "was             → be\n",
            "then            → then\n",
            "followed        → follow\n",
            "by              → by\n",
            "something       → something\n",
            "more            → more\n",
            "grand           → grand\n",
            "and             → and\n",
            "even            → even\n",
            "better          → well\n",
            ".               → .\n",
            "added positive, for word: fantastic\n",
            "added positive, for word: nice\n",
            "reviewTokens:\n",
            "['it', 'be', 'a', 'more', 'concentrated', 'and', 'slightly', 'simple', 'game', 'than', 'its', 'brilliant', 'second', 'instalment', ',', 'which', 'really', 'expand', 'every', 'part', 'and', 'be', 'well', 'in', 'my', 'opinion', '.', 'but', 'if', 'you', 'scale', 'it', 'all', 'down', ',', 'it', 'be', 'still', 'the', 'same', 'concept', '.', 'you', 'be', 'treat', 'to', 'fantastic', 'puzzle', 'and', 'a', 'really', 'nice', 'facelift', 'that', 'make', 'it', 'definitely', 'worth', 'experience', '.', 'even', 'if', 'it', 'be', 'then', 'follow', 'by', 'something', 'more', 'grand', 'and', 'even', 'well', '.']\n",
            "positive, negative 2 0\n",
            "--------------------------------------------------------------\n",
            "review text:  Where Winds Meet is over-ambitious, messy, opaque, and inconsistent. It has too many gears that don’t mesh, a lot that’s poorly explained, and it refuses to give the player a moment of unproductive time, even at the cost of coherence and comprehensibility. For all that, Where Winds Meet is a lot of fun. It often looks incredible and the world is certainly filled with content, whether for a single player or in a group. Even without touching the cash shop, Where Winds Meet provides a huge amount of free game play. Right now, Where Winds Meet is a little shy of greatness, but with some technical improvements and time it could get there.\n",
            "lematization:\n",
            "Where           → where\n",
            "Winds           → Winds\n",
            "Meet            → Meet\n",
            "is              → be\n",
            "over            → over\n",
            "-               → -\n",
            "ambitious       → ambitious\n",
            ",               → ,\n",
            "messy           → messy\n",
            ",               → ,\n",
            "opaque          → opaque\n",
            ",               → ,\n",
            "and             → and\n",
            "inconsistent    → inconsistent\n",
            ".               → .\n",
            "It              → it\n",
            "has             → have\n",
            "too             → too\n",
            "many            → many\n",
            "gears           → gear\n",
            "that            → that\n",
            "do              → do\n",
            "n’t             → n’t\n",
            "mesh            → mesh\n",
            ",               → ,\n",
            "a               → a\n",
            "lot             → lot\n",
            "that            → that\n",
            "’s              → ’s\n",
            "poorly          → poorly\n",
            "explained       → explain\n",
            ",               → ,\n",
            "and             → and\n",
            "it              → it\n",
            "refuses         → refuse\n",
            "to              → to\n",
            "give            → give\n",
            "the             → the\n",
            "player          → player\n",
            "a               → a\n",
            "moment          → moment\n",
            "of              → of\n",
            "unproductive    → unproductive\n",
            "time            → time\n",
            ",               → ,\n",
            "even            → even\n",
            "at              → at\n",
            "the             → the\n",
            "cost            → cost\n",
            "of              → of\n",
            "coherence       → coherence\n",
            "and             → and\n",
            "comprehensibility → comprehensibility\n",
            ".               → .\n",
            "For             → for\n",
            "all             → all\n",
            "that            → that\n",
            ",               → ,\n",
            "Where           → where\n",
            "Winds           → Winds\n",
            "Meet            → Meet\n",
            "is              → be\n",
            "a               → a\n",
            "lot             → lot\n",
            "of              → of\n",
            "fun             → fun\n",
            ".               → .\n",
            "It              → it\n",
            "often           → often\n",
            "looks           → look\n",
            "incredible      → incredible\n",
            "and             → and\n",
            "the             → the\n",
            "world           → world\n",
            "is              → be\n",
            "certainly       → certainly\n",
            "filled          → fill\n",
            "with            → with\n",
            "content         → content\n",
            ",               → ,\n",
            "whether         → whether\n",
            "for             → for\n",
            "a               → a\n",
            "single          → single\n",
            "player          → player\n",
            "or              → or\n",
            "in              → in\n",
            "a               → a\n",
            "group           → group\n",
            ".               → .\n",
            "Even            → even\n",
            "without         → without\n",
            "touching        → touch\n",
            "the             → the\n",
            "cash            → cash\n",
            "shop            → shop\n",
            ",               → ,\n",
            "Where           → where\n",
            "Winds           → Winds\n",
            "Meet            → Meet\n",
            "provides        → provide\n",
            "a               → a\n",
            "huge            → huge\n",
            "amount          → amount\n",
            "of              → of\n",
            "free            → free\n",
            "game            → game\n",
            "play            → play\n",
            ".               → .\n",
            "Right           → right\n",
            "now             → now\n",
            ",               → ,\n",
            "Where           → where\n",
            "Winds           → Winds\n",
            "Meet            → Meet\n",
            "is              → be\n",
            "a               → a\n",
            "little          → little\n",
            "shy             → shy\n",
            "of              → of\n",
            "greatness       → greatness\n",
            ",               → ,\n",
            "but             → but\n",
            "with            → with\n",
            "some            → some\n",
            "technical       → technical\n",
            "improvements    → improvement\n",
            "and             → and\n",
            "time            → time\n",
            "it              → it\n",
            "could           → could\n",
            "get             → get\n",
            "there           → there\n",
            ".               → .\n",
            "added positive, for word: incredible\n",
            "reviewTokens:\n",
            "['where', 'Winds', 'Meet', 'be', 'over', '-', 'ambitious', ',', 'messy', ',', 'opaque', ',', 'and', 'inconsistent', '.', 'it', 'have', 'too', 'many', 'gear', 'that', 'do', 'n’t', 'mesh', ',', 'a', 'lot', 'that', '’s', 'poorly', 'explain', ',', 'and', 'it', 'refuse', 'to', 'give', 'the', 'player', 'a', 'moment', 'of', 'unproductive', 'time', ',', 'even', 'at', 'the', 'cost', 'of', 'coherence', 'and', 'comprehensibility', '.', 'for', 'all', 'that', ',', 'where', 'Winds', 'Meet', 'be', 'a', 'lot', 'of', 'fun', '.', 'it', 'often', 'look', 'incredible', 'and', 'the', 'world', 'be', 'certainly', 'fill', 'with', 'content', ',', 'whether', 'for', 'a', 'single', 'player', 'or', 'in', 'a', 'group', '.', 'even', 'without', 'touch', 'the', 'cash', 'shop', ',', 'where', 'Winds', 'Meet', 'provide', 'a', 'huge', 'amount', 'of', 'free', 'game', 'play', '.', 'right', 'now', ',', 'where', 'Winds', 'Meet', 'be', 'a', 'little', 'shy', 'of', 'greatness', ',', 'but', 'with', 'some', 'technical', 'improvement', 'and', 'time', 'it', 'could', 'get', 'there', '.']\n",
            "positive, negative 1 0\n",
            "--------------------------------------------------------------\n",
            "review text:  Park Chan-wook’s Oldboy may frequently shock and disgust you, but you’ll find yourself unable to look away from the excellent filmmaking on display.\n",
            "lematization:\n",
            "Park            → Park\n",
            "Chan            → Chan\n",
            "-               → -\n",
            "wook            → wook\n",
            "’s              → ’s\n",
            "Oldboy          → Oldboy\n",
            "may             → may\n",
            "frequently      → frequently\n",
            "shock           → shock\n",
            "and             → and\n",
            "disgust         → disgust\n",
            "you             → you\n",
            ",               → ,\n",
            "but             → but\n",
            "you             → you\n",
            "’ll             → ’ll\n",
            "find            → find\n",
            "yourself        → yourself\n",
            "unable          → unable\n",
            "to              → to\n",
            "look            → look\n",
            "away            → away\n",
            "from            → from\n",
            "the             → the\n",
            "excellent       → excellent\n",
            "filmmaking      → filmmaking\n",
            "on              → on\n",
            "display         → display\n",
            ".               → .\n",
            "added negative, for word: disgust\n",
            "added positive, for word: excellent\n",
            "reviewTokens:\n",
            "['Park', 'Chan', '-', 'wook', '’s', 'Oldboy', 'may', 'frequently', 'shock', 'and', 'disgust', 'you', ',', 'but', 'you', '’ll', 'find', 'yourself', 'unable', 'to', 'look', 'away', 'from', 'the', 'excellent', 'filmmaking', 'on', 'display', '.']\n",
            "positive, negative 1 1\n",
            "--------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Moj zaključak je da je ovakav pristup uredu kao početak ali za definitivan zaključak tona potreban je kontekts, pogotovo što se tiče recenzija Filmova, gdje određen vokabular ne mora biti negativan iako može biti individualno interpretiran kao takav.\n",
        "\n",
        "primjer za Oldboy:\n",
        "\n",
        "negative: disgust\n",
        "positive: excellent\n",
        "\n",
        "review text:  Park Chan-wook’s Oldboy may frequently shock and disgust you, but you’ll find yourself unable to look away from the excellent filmmaking on display.\n",
        "\n",
        "positive, negative 1 1"
      ],
      "metadata": {
        "id": "SUoUXyhuXctW"
      },
      "id": "SUoUXyhuXctW"
    },
    {
      "cell_type": "markdown",
      "id": "29571374",
      "metadata": {
        "id": "29571374"
      },
      "source": [
        "## Zadatak 3: Uredi nered/pronađi lažne riječi\n",
        "\n",
        "**Opis:**  \n",
        "Zadan je tekst koji sadrži izmišljene riječi ili “šum”.  \n",
        "Zadatak je pronaći riječi koje nisu prepoznate u jezičnom modelu (engl. *out of vocabulary words*).\n",
        "\n",
        "**Cilj:**  \n",
        "Razumjeti kako model prepoznaje poznate i nepoznate riječi te kako to može pomoći u detekciji pogrešaka u tekstu.\n",
        "\n",
        "**Upute:**  \n",
        "1. Unesi tekst koji sadrži besmislene riječi (npr. „The data blorp is analyzed using great accuracy flom.“).  \n",
        "2. Tokeniziraj tekst pomoću spaCy modela.  \n",
        "3. Provjeri svaku riječ pomoću `token.is_oov`, ako vrati `True`, riječ nije prepoznata.  \n",
        "4. Ispiši popis “nepoznatih” riječi.  \n",
        "5. (Opcionalno) Očisti tekst uklanjanjem tih riječi."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24cce210",
      "metadata": {
        "id": "24cce210"
      },
      "source": [
        "**Tekst:**\n",
        "\n",
        "> In the future, artificel intellgence will revolutionize the way we interract with technolodgy.  \n",
        "> Peaple might use smart assistents not only for work but also for personal healtcare and educattion.  \n",
        "> Yet, as systems become more compicated, ensuring data privasy and securrity will be crucial.  \n",
        "> The recent blonix project already shows how mashine learning can adapt to dynamic enviroments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "70699761",
      "metadata": {
        "id": "70699761",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcc9994d-7239-4f2e-c4a0-72f949931006"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-md==3.8.0\n",
            "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.8.0/en_core_web_md-3.8.0-py3-none-any.whl (33.5 MB)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "text = \"\"\"\n",
        "In the future, artificel intellgence will revolutionize the way we interract with technolodgy.\n",
        "Peaple might use smart assistents not only for work but also for personal healtcare and educattion.\n",
        "Yet, as systems become more compicated, ensuring data privasy and securrity will be crucial.\n",
        "The recent blonix project already shows how mashine learning can adapt to dynamic enviroments.\n",
        "\"\"\"\n",
        "\n",
        "!python -m spacy download en_core_web_md\n",
        "\n",
        "nlp = spacy.load('en_core_web_md')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_tech = nlp(text)\n",
        "for token in doc_tech:\n",
        "    print(token.text)\n",
        "\n",
        "unknown = []\n",
        "\n",
        "doc_tech = nlp(text)\n",
        "for token in doc_tech:\n",
        "    if(token.is_oov):\n",
        "      print(\"nepoznata rijec :\",token.text)\n",
        "      unknown.append(token.text)\n",
        "\n",
        "print(\"nepoznate rijeci: \",unknown)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJG0i5nkYLB3",
        "outputId": "ddf2ccfd-b081-49a1-8f4b-c31b32517290"
      },
      "id": "DJG0i5nkYLB3",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "In\n",
            "the\n",
            "future\n",
            ",\n",
            "artificel\n",
            "intellgence\n",
            "will\n",
            "revolutionize\n",
            "the\n",
            "way\n",
            "we\n",
            "interract\n",
            "with\n",
            "technolodgy\n",
            ".\n",
            "\n",
            "\n",
            "Peaple\n",
            "might\n",
            "use\n",
            "smart\n",
            "assistents\n",
            "not\n",
            "only\n",
            "for\n",
            "work\n",
            "but\n",
            "also\n",
            "for\n",
            "personal\n",
            "healtcare\n",
            "and\n",
            "educattion\n",
            ".\n",
            "\n",
            "\n",
            "Yet\n",
            ",\n",
            "as\n",
            "systems\n",
            "become\n",
            "more\n",
            "compicated\n",
            ",\n",
            "ensuring\n",
            "data\n",
            "privasy\n",
            "and\n",
            "securrity\n",
            "will\n",
            "be\n",
            "crucial\n",
            ".\n",
            "\n",
            "\n",
            "The\n",
            "recent\n",
            "blonix\n",
            "project\n",
            "already\n",
            "shows\n",
            "how\n",
            "mashine\n",
            "learning\n",
            "can\n",
            "adapt\n",
            "to\n",
            "dynamic\n",
            "enviroments\n",
            ".\n",
            "\n",
            "\n",
            "nepoznata rijec : \n",
            "\n",
            "nepoznata rijec : artificel\n",
            "nepoznata rijec : technolodgy\n",
            "nepoznata rijec : \n",
            "\n",
            "nepoznata rijec : Peaple\n",
            "nepoznata rijec : assistents\n",
            "nepoznata rijec : educattion\n",
            "nepoznata rijec : \n",
            "\n",
            "nepoznata rijec : privasy\n",
            "nepoznata rijec : securrity\n",
            "nepoznata rijec : \n",
            "\n",
            "nepoznata rijec : blonix\n",
            "nepoznata rijec : \n",
            "\n",
            "nepoznate rijeci:  ['\\n', 'artificel', 'technolodgy', '\\n', 'Peaple', 'assistents', 'educattion', '\\n', 'privasy', 'securrity', '\\n', 'blonix', '\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Potrebno je bilo promjeniti na en_core_web_md jer en_core_web_sm je svaku riječ klasificirao kao nepoznatu po token.is_oov"
      ],
      "metadata": {
        "id": "vuA4Q9BbZpmn"
      },
      "id": "vuA4Q9BbZpmn"
    },
    {
      "cell_type": "markdown",
      "id": "6079cbe4",
      "metadata": {
        "id": "6079cbe4"
      },
      "source": [
        "## Zadatak 4: Tko govori o čemu?\n",
        "\n",
        "**Opis:**  \n",
        "Imate tri različita teksta iz različitih domena (npr. politika, sport, znanost).  \n",
        "Nakon obrade potrebno je prepoznati kojoj temi pojedini tekst pripada, koristeći najčešće riječi.\n",
        "\n",
        "**Cilj:**  \n",
        "Povezati statističku analizu riječi s prepoznavanjem teme teksta —> osnova za automatsku klasifikaciju dokumenata.\n",
        "\n",
        "**Upute:**  \n",
        "1. Pripremi tri teksta različitih tema.  \n",
        "2. Obradi svaki tekst kroz cijeli NLP postupak.  \n",
        "3. Izvuci 5 najčešćih imenica i glagola.  \n",
        "4. Na temelju tih riječi pokušaj zaključiti o čemu tekst govori.  \n",
        "5. (Opcionalno) Napravi jednostavan graf koji prikazuje razlike među tekstovima."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "72eb1ec9",
      "metadata": {
        "id": "72eb1ec9"
      },
      "outputs": [],
      "source": [
        "text1 = \"\"\"\n",
        "The government has introduced a series of new reforms designed to improve economic stability and strengthen national policy.\n",
        "According to officials, the government believes these reforms will help reduce inflation and increase trust in public institutions.\n",
        "During a press conference, government representatives explained that the policy focuses on long-term economic growth, responsible budgeting, and transparent decision-making.\n",
        "Opposition leaders criticized the government, arguing that the reforms do not address the root causes of inflation and may place additional pressure on the middle-class population.\n",
        "Despite the criticism, the prime minister emphasized that the government must take decisive action to protect the economy.\n",
        "He stated that the policy is essential for maintaining stability, supporting national programs, and ensuring that citizens benefit from a more resilient economic system.\n",
        "The government also announced consultations with economic experts to refine the policy and monitor inflation trends.\n",
        "Overall, the government insists that the reforms represent a necessary step toward financial responsibility and sustainable development.\n",
        "\"\"\"\n",
        "\n",
        "text2 = \"\"\"\n",
        "The team delivered an outstanding performance last night, playing one of the most intense matches of the season.\n",
        "Throughout the match, the team showed great determination, teamwork, and discipline.\n",
        "The coach praised the team for maintaining focus and adapting their strategy as the match progressed.\n",
        "Fans celebrated loudly, recognizing that the team’s victory was crucial for securing their position in the championship rankings.\n",
        "During the post-match interview, the coach highlighted how preparation and teamwork were essential for winning such a competitive match.\n",
        "Several players said that the team felt more united than ever, and that their teamwork was the key factor in overcoming the toughest opponents.\n",
        "The next match will be even more important, as the team aims to qualify for the finals.\n",
        "If the team continues to play with this level of teamwork and discipline, they have a strong chance of winning the entire championship.\n",
        "\"\"\"\n",
        "\n",
        "text3 = \"\"\"\n",
        "Researchers at the university have developed a new material that significantly improves energy storage efficiency.\n",
        "The material was tested under various laboratory conditions, and researchers observed that the material maintained its structure even when exposed to high temperatures.\n",
        "According to the study, the material could transform the future of renewable energy by enabling more stable and long-lasting storage systems.\n",
        "Scientists believe that energy demand will continue to rise, making the development of advanced material technologies essential for sustainable production.\n",
        "The research team plans to publish additional data as they continue studying the material and its impact on battery performance.\n",
        "Several researchers have already suggested that this material could replace current lithium-based components used in many energy systems.\n",
        "If the material continues to show positive results, it may revolutionize energy production and create new opportunities for scientific innovation.\n",
        "Overall, the study highlights the importance of energy research and the potential of this new material to reshape modern technology.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [text1,text2,text3]\n",
        "\n",
        "for text in texts:\n",
        "  myText = text\n",
        "  print(\"text: \", myText)\n",
        "  doc = nlp(myText)\n",
        "  filtered_spacy = [token.text for token in doc if not token.is_stop]\n",
        "  print(\"lematization:\")\n",
        "  for token in doc:\n",
        "    print(f'{token.text:15} → {token.lemma_}')\n",
        "\n",
        "  nouns = []\n",
        "  verbs = []\n",
        "\n",
        "  for token in doc:\n",
        "    if(token.pos_ == \"NOUN\"):\n",
        "      nouns.append(token.lemma_)\n",
        "    if(token.pos_ == \"VERB\"):\n",
        "      verbs.append(token.lemma_)\n",
        "\n",
        "  noun_counter = Counter(nouns)\n",
        "  verb_counter = Counter(verbs)\n",
        "\n",
        "  top5_nouns = noun_counter.most_common(5)\n",
        "  top5_verbs = verb_counter.most_common(5)\n",
        "\n",
        "  print(\"top 5 nouns:\")\n",
        "  print(top5_nouns)\n",
        "  print(\"top 5 verbs:\")\n",
        "  print(top5_verbs)\n",
        "\n",
        "  print(\"--------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnJKJwjhZ7r8",
        "outputId": "7af0fde7-021a-4c08-b1a6-8b87ec11ba67"
      },
      "id": "qnJKJwjhZ7r8",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text:  \n",
            "The government has introduced a series of new reforms designed to improve economic stability and strengthen national policy.\n",
            "According to officials, the government believes these reforms will help reduce inflation and increase trust in public institutions.\n",
            "During a press conference, government representatives explained that the policy focuses on long-term economic growth, responsible budgeting, and transparent decision-making.\n",
            "Opposition leaders criticized the government, arguing that the reforms do not address the root causes of inflation and may place additional pressure on the middle-class population.\n",
            "Despite the criticism, the prime minister emphasized that the government must take decisive action to protect the economy.\n",
            "He stated that the policy is essential for maintaining stability, supporting national programs, and ensuring that citizens benefit from a more resilient economic system.\n",
            "The government also announced consultations with economic experts to refine the policy and monitor inflation trends.\n",
            "Overall, the government insists that the reforms represent a necessary step toward financial responsibility and sustainable development.\n",
            "\n",
            "lematization:\n",
            "\n",
            "               → \n",
            "\n",
            "The             → the\n",
            "government      → government\n",
            "has             → have\n",
            "introduced      → introduce\n",
            "a               → a\n",
            "series          → series\n",
            "of              → of\n",
            "new             → new\n",
            "reforms         → reform\n",
            "designed        → design\n",
            "to              → to\n",
            "improve         → improve\n",
            "economic        → economic\n",
            "stability       → stability\n",
            "and             → and\n",
            "strengthen      → strengthen\n",
            "national        → national\n",
            "policy          → policy\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "According       → accord\n",
            "to              → to\n",
            "officials       → official\n",
            ",               → ,\n",
            "the             → the\n",
            "government      → government\n",
            "believes        → believe\n",
            "these           → these\n",
            "reforms         → reform\n",
            "will            → will\n",
            "help            → help\n",
            "reduce          → reduce\n",
            "inflation       → inflation\n",
            "and             → and\n",
            "increase        → increase\n",
            "trust           → trust\n",
            "in              → in\n",
            "public          → public\n",
            "institutions    → institution\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "During          → during\n",
            "a               → a\n",
            "press           → press\n",
            "conference      → conference\n",
            ",               → ,\n",
            "government      → government\n",
            "representatives → representative\n",
            "explained       → explain\n",
            "that            → that\n",
            "the             → the\n",
            "policy          → policy\n",
            "focuses         → focus\n",
            "on              → on\n",
            "long            → long\n",
            "-               → -\n",
            "term            → term\n",
            "economic        → economic\n",
            "growth          → growth\n",
            ",               → ,\n",
            "responsible     → responsible\n",
            "budgeting       → budgeting\n",
            ",               → ,\n",
            "and             → and\n",
            "transparent     → transparent\n",
            "decision        → decision\n",
            "-               → -\n",
            "making          → making\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "Opposition      → opposition\n",
            "leaders         → leader\n",
            "criticized      → criticize\n",
            "the             → the\n",
            "government      → government\n",
            ",               → ,\n",
            "arguing         → argue\n",
            "that            → that\n",
            "the             → the\n",
            "reforms         → reform\n",
            "do              → do\n",
            "not             → not\n",
            "address         → address\n",
            "the             → the\n",
            "root            → root\n",
            "causes          → cause\n",
            "of              → of\n",
            "inflation       → inflation\n",
            "and             → and\n",
            "may             → may\n",
            "place           → place\n",
            "additional      → additional\n",
            "pressure        → pressure\n",
            "on              → on\n",
            "the             → the\n",
            "middle          → middle\n",
            "-               → -\n",
            "class           → class\n",
            "population      → population\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "Despite         → despite\n",
            "the             → the\n",
            "criticism       → criticism\n",
            ",               → ,\n",
            "the             → the\n",
            "prime           → prime\n",
            "minister        → minister\n",
            "emphasized      → emphasize\n",
            "that            → that\n",
            "the             → the\n",
            "government      → government\n",
            "must            → must\n",
            "take            → take\n",
            "decisive        → decisive\n",
            "action          → action\n",
            "to              → to\n",
            "protect         → protect\n",
            "the             → the\n",
            "economy         → economy\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "He              → he\n",
            "stated          → state\n",
            "that            → that\n",
            "the             → the\n",
            "policy          → policy\n",
            "is              → be\n",
            "essential       → essential\n",
            "for             → for\n",
            "maintaining     → maintain\n",
            "stability       → stability\n",
            ",               → ,\n",
            "supporting      → support\n",
            "national        → national\n",
            "programs        → program\n",
            ",               → ,\n",
            "and             → and\n",
            "ensuring        → ensure\n",
            "that            → that\n",
            "citizens        → citizen\n",
            "benefit         → benefit\n",
            "from            → from\n",
            "a               → a\n",
            "more            → more\n",
            "resilient       → resilient\n",
            "economic        → economic\n",
            "system          → system\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "The             → the\n",
            "government      → government\n",
            "also            → also\n",
            "announced       → announce\n",
            "consultations   → consultation\n",
            "with            → with\n",
            "economic        → economic\n",
            "experts         → expert\n",
            "to              → to\n",
            "refine          → refine\n",
            "the             → the\n",
            "policy          → policy\n",
            "and             → and\n",
            "monitor         → monitor\n",
            "inflation       → inflation\n",
            "trends          → trend\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "Overall         → overall\n",
            ",               → ,\n",
            "the             → the\n",
            "government      → government\n",
            "insists         → insist\n",
            "that            → that\n",
            "the             → the\n",
            "reforms         → reform\n",
            "represent       → represent\n",
            "a               → a\n",
            "necessary       → necessary\n",
            "step            → step\n",
            "toward          → toward\n",
            "financial       → financial\n",
            "responsibility  → responsibility\n",
            "and             → and\n",
            "sustainable     → sustainable\n",
            "development     → development\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "top 5 nouns:\n",
            "[('government', 7), ('reform', 4), ('policy', 4), ('inflation', 3), ('stability', 2)]\n",
            "top 5 verbs:\n",
            "[('introduce', 1), ('design', 1), ('improve', 1), ('strengthen', 1), ('accord', 1)]\n",
            "--------------------------------------------------------------\n",
            "text:  \n",
            "The team delivered an outstanding performance last night, playing one of the most intense matches of the season.\n",
            "Throughout the match, the team showed great determination, teamwork, and discipline.\n",
            "The coach praised the team for maintaining focus and adapting their strategy as the match progressed.\n",
            "Fans celebrated loudly, recognizing that the team’s victory was crucial for securing their position in the championship rankings.\n",
            "During the post-match interview, the coach highlighted how preparation and teamwork were essential for winning such a competitive match.\n",
            "Several players said that the team felt more united than ever, and that their teamwork was the key factor in overcoming the toughest opponents.\n",
            "The next match will be even more important, as the team aims to qualify for the finals.\n",
            "If the team continues to play with this level of teamwork and discipline, they have a strong chance of winning the entire championship.\n",
            "\n",
            "lematization:\n",
            "\n",
            "               → \n",
            "\n",
            "The             → the\n",
            "team            → team\n",
            "delivered       → deliver\n",
            "an              → an\n",
            "outstanding     → outstanding\n",
            "performance     → performance\n",
            "last            → last\n",
            "night           → night\n",
            ",               → ,\n",
            "playing         → play\n",
            "one             → one\n",
            "of              → of\n",
            "the             → the\n",
            "most            → most\n",
            "intense         → intense\n",
            "matches         → match\n",
            "of              → of\n",
            "the             → the\n",
            "season          → season\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "Throughout      → throughout\n",
            "the             → the\n",
            "match           → match\n",
            ",               → ,\n",
            "the             → the\n",
            "team            → team\n",
            "showed          → show\n",
            "great           → great\n",
            "determination   → determination\n",
            ",               → ,\n",
            "teamwork        → teamwork\n",
            ",               → ,\n",
            "and             → and\n",
            "discipline      → discipline\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "The             → the\n",
            "coach           → coach\n",
            "praised         → praise\n",
            "the             → the\n",
            "team            → team\n",
            "for             → for\n",
            "maintaining     → maintain\n",
            "focus           → focus\n",
            "and             → and\n",
            "adapting        → adapt\n",
            "their           → their\n",
            "strategy        → strategy\n",
            "as              → as\n",
            "the             → the\n",
            "match           → match\n",
            "progressed      → progress\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "Fans            → fan\n",
            "celebrated      → celebrate\n",
            "loudly          → loudly\n",
            ",               → ,\n",
            "recognizing     → recognize\n",
            "that            → that\n",
            "the             → the\n",
            "team            → team\n",
            "’s              → ’s\n",
            "victory         → victory\n",
            "was             → be\n",
            "crucial         → crucial\n",
            "for             → for\n",
            "securing        → secure\n",
            "their           → their\n",
            "position        → position\n",
            "in              → in\n",
            "the             → the\n",
            "championship    → championship\n",
            "rankings        → ranking\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "During          → during\n",
            "the             → the\n",
            "post            → post\n",
            "-               → -\n",
            "match           → match\n",
            "interview       → interview\n",
            ",               → ,\n",
            "the             → the\n",
            "coach           → coach\n",
            "highlighted     → highlight\n",
            "how             → how\n",
            "preparation     → preparation\n",
            "and             → and\n",
            "teamwork        → teamwork\n",
            "were            → be\n",
            "essential       → essential\n",
            "for             → for\n",
            "winning         → win\n",
            "such            → such\n",
            "a               → a\n",
            "competitive     → competitive\n",
            "match           → match\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "Several         → several\n",
            "players         → player\n",
            "said            → say\n",
            "that            → that\n",
            "the             → the\n",
            "team            → team\n",
            "felt            → feel\n",
            "more            → more\n",
            "united          → united\n",
            "than            → than\n",
            "ever            → ever\n",
            ",               → ,\n",
            "and             → and\n",
            "that            → that\n",
            "their           → their\n",
            "teamwork        → teamwork\n",
            "was             → be\n",
            "the             → the\n",
            "key             → key\n",
            "factor          → factor\n",
            "in              → in\n",
            "overcoming      → overcome\n",
            "the             → the\n",
            "toughest        → tough\n",
            "opponents       → opponent\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "The             → the\n",
            "next            → next\n",
            "match           → match\n",
            "will            → will\n",
            "be              → be\n",
            "even            → even\n",
            "more            → more\n",
            "important       → important\n",
            ",               → ,\n",
            "as              → as\n",
            "the             → the\n",
            "team            → team\n",
            "aims            → aim\n",
            "to              → to\n",
            "qualify         → qualify\n",
            "for             → for\n",
            "the             → the\n",
            "finals          → final\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "If              → if\n",
            "the             → the\n",
            "team            → team\n",
            "continues       → continue\n",
            "to              → to\n",
            "play            → play\n",
            "with            → with\n",
            "this            → this\n",
            "level           → level\n",
            "of              → of\n",
            "teamwork        → teamwork\n",
            "and             → and\n",
            "discipline      → discipline\n",
            ",               → ,\n",
            "they            → they\n",
            "have            → have\n",
            "a               → a\n",
            "strong          → strong\n",
            "chance          → chance\n",
            "of              → of\n",
            "winning         → win\n",
            "the             → the\n",
            "entire          → entire\n",
            "championship    → championship\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "top 5 nouns:\n",
            "[('team', 7), ('match', 5), ('teamwork', 4), ('discipline', 2), ('coach', 2)]\n",
            "top 5 verbs:\n",
            "[('play', 2), ('win', 2), ('deliver', 1), ('show', 1), ('praise', 1)]\n",
            "--------------------------------------------------------------\n",
            "text:  \n",
            "Researchers at the university have developed a new material that significantly improves energy storage efficiency.\n",
            "The material was tested under various laboratory conditions, and researchers observed that the material maintained its structure even when exposed to high temperatures.\n",
            "According to the study, the material could transform the future of renewable energy by enabling more stable and long-lasting storage systems.\n",
            "Scientists believe that energy demand will continue to rise, making the development of advanced material technologies essential for sustainable production.\n",
            "The research team plans to publish additional data as they continue studying the material and its impact on battery performance.\n",
            "Several researchers have already suggested that this material could replace current lithium-based components used in many energy systems.\n",
            "If the material continues to show positive results, it may revolutionize energy production and create new opportunities for scientific innovation.\n",
            "Overall, the study highlights the importance of energy research and the potential of this new material to reshape modern technology.\n",
            "\n",
            "lematization:\n",
            "\n",
            "               → \n",
            "\n",
            "Researchers     → Researchers\n",
            "at              → at\n",
            "the             → the\n",
            "university      → university\n",
            "have            → have\n",
            "developed       → develop\n",
            "a               → a\n",
            "new             → new\n",
            "material        → material\n",
            "that            → that\n",
            "significantly   → significantly\n",
            "improves        → improve\n",
            "energy          → energy\n",
            "storage         → storage\n",
            "efficiency      → efficiency\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "The             → the\n",
            "material        → material\n",
            "was             → be\n",
            "tested          → test\n",
            "under           → under\n",
            "various         → various\n",
            "laboratory      → laboratory\n",
            "conditions      → condition\n",
            ",               → ,\n",
            "and             → and\n",
            "researchers     → researcher\n",
            "observed        → observe\n",
            "that            → that\n",
            "the             → the\n",
            "material        → material\n",
            "maintained      → maintain\n",
            "its             → its\n",
            "structure       → structure\n",
            "even            → even\n",
            "when            → when\n",
            "exposed         → expose\n",
            "to              → to\n",
            "high            → high\n",
            "temperatures    → temperature\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "According       → accord\n",
            "to              → to\n",
            "the             → the\n",
            "study           → study\n",
            ",               → ,\n",
            "the             → the\n",
            "material        → material\n",
            "could           → could\n",
            "transform       → transform\n",
            "the             → the\n",
            "future          → future\n",
            "of              → of\n",
            "renewable       → renewable\n",
            "energy          → energy\n",
            "by              → by\n",
            "enabling        → enable\n",
            "more            → more\n",
            "stable          → stable\n",
            "and             → and\n",
            "long            → long\n",
            "-               → -\n",
            "lasting         → last\n",
            "storage         → storage\n",
            "systems         → system\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "Scientists      → scientist\n",
            "believe         → believe\n",
            "that            → that\n",
            "energy          → energy\n",
            "demand          → demand\n",
            "will            → will\n",
            "continue        → continue\n",
            "to              → to\n",
            "rise            → rise\n",
            ",               → ,\n",
            "making          → make\n",
            "the             → the\n",
            "development     → development\n",
            "of              → of\n",
            "advanced        → advanced\n",
            "material        → material\n",
            "technologies    → technology\n",
            "essential       → essential\n",
            "for             → for\n",
            "sustainable     → sustainable\n",
            "production      → production\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "The             → the\n",
            "research        → research\n",
            "team            → team\n",
            "plans           → plan\n",
            "to              → to\n",
            "publish         → publish\n",
            "additional      → additional\n",
            "data            → datum\n",
            "as              → as\n",
            "they            → they\n",
            "continue        → continue\n",
            "studying        → study\n",
            "the             → the\n",
            "material        → material\n",
            "and             → and\n",
            "its             → its\n",
            "impact          → impact\n",
            "on              → on\n",
            "battery         → battery\n",
            "performance     → performance\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "Several         → several\n",
            "researchers     → researcher\n",
            "have            → have\n",
            "already         → already\n",
            "suggested       → suggest\n",
            "that            → that\n",
            "this            → this\n",
            "material        → material\n",
            "could           → could\n",
            "replace         → replace\n",
            "current         → current\n",
            "lithium         → lithium\n",
            "-               → -\n",
            "based           → base\n",
            "components      → component\n",
            "used            → use\n",
            "in              → in\n",
            "many            → many\n",
            "energy          → energy\n",
            "systems         → system\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "If              → if\n",
            "the             → the\n",
            "material        → material\n",
            "continues       → continue\n",
            "to              → to\n",
            "show            → show\n",
            "positive        → positive\n",
            "results         → result\n",
            ",               → ,\n",
            "it              → it\n",
            "may             → may\n",
            "revolutionize   → revolutionize\n",
            "energy          → energy\n",
            "production      → production\n",
            "and             → and\n",
            "create          → create\n",
            "new             → new\n",
            "opportunities   → opportunity\n",
            "for             → for\n",
            "scientific      → scientific\n",
            "innovation      → innovation\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "Overall         → overall\n",
            ",               → ,\n",
            "the             → the\n",
            "study           → study\n",
            "highlights      → highlight\n",
            "the             → the\n",
            "importance      → importance\n",
            "of              → of\n",
            "energy          → energy\n",
            "research        → research\n",
            "and             → and\n",
            "the             → the\n",
            "potential       → potential\n",
            "of              → of\n",
            "this            → this\n",
            "new             → new\n",
            "material        → material\n",
            "to              → to\n",
            "reshape         → reshape\n",
            "modern          → modern\n",
            "technology      → technology\n",
            ".               → .\n",
            "\n",
            "               → \n",
            "\n",
            "top 5 nouns:\n",
            "[('material', 9), ('energy', 6), ('storage', 2), ('researcher', 2), ('study', 2)]\n",
            "top 5 verbs:\n",
            "[('continue', 3), ('develop', 1), ('improve', 1), ('test', 1), ('observe', 1)]\n",
            "--------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Texgt 1:\n",
        "\n",
        "top 5 nouns:\n",
        "[('government', 7), ('reform', 4), ('policy', 4), ('inflation', 3), ('stability', 2)]\n",
        "top 5 verbs:\n",
        "[('introduce', 1), ('design', 1), ('improve', 1), ('strengthen', 1), ('accord', 1)]\n",
        "\n",
        "\n",
        "Bazirano na ovim riječima moj zaključak je da je tekst politčki nastrojen, konkretno možda o ekonomiji\n",
        "\n",
        "Text 2:\n",
        "\n",
        "top 5 nouns:\n",
        "[('team', 7), ('match', 5), ('teamwork', 4), ('discipline', 2), ('coach', 2)]\n",
        "top 5 verbs:\n",
        "[('play', 2), ('win', 2), ('deliver', 1), ('show', 1), ('praise', 1)]\n",
        "\n",
        "Bazirano na ovim riječima moj zaključak je da je tekst o sportu\n",
        "\n",
        "Text 3 :\n",
        "\n",
        "top 5 nouns:\n",
        "[('material', 9), ('energy', 6), ('storage', 2), ('researcher', 2), ('study', 2)]\n",
        "top 5 verbs:\n",
        "[('continue', 3), ('develop', 1), ('improve', 1), ('test', 1), ('observe', 1)]\n",
        "\n",
        "Bazirano na ovim riječima moj zaključak je da je tekst znanstveni nastrojen, konkretno možda o nekakvom istraživanju o elektranama"
      ],
      "metadata": {
        "id": "5DDxGlWUcUqW"
      },
      "id": "5DDxGlWUcUqW"
    },
    {
      "cell_type": "markdown",
      "id": "3a023ccd",
      "metadata": {
        "id": "3a023ccd"
      },
      "source": [
        "## Zadatak 5: Analiza političkih govora (napredni zadatak)\n",
        "\n",
        "> **Opis:**  \n",
        "> U ovom zadatku treba analizirati tekstove političkih govora i otkriti koje riječi govornici najčešće koriste kako bi naglasili svoje poruke.  \n",
        "> Cilj je otkriti koje teme i koje vrste riječi dominiraju u govoru.\n",
        "\n",
        "---\n",
        "\n",
        "**Upute:**\n",
        "1. Pronađi ili kopiraj dva kratka govora (ili odlomka) poznatih političara.  \n",
        "   Ako nemaš stvarne govore, možeš koristiti dva primjera niže.  \n",
        "2. Za svaki govor napravi kompletnu obradu teksta:\n",
        "   - tokenizacija  \n",
        "   - uklanjanje zaustavnih riječi  \n",
        "   - lematizacija  \n",
        "   - POS tagging  \n",
        "3. Izdvoji:\n",
        "   - 10 **imenica**,  \n",
        "   - 10 **glagola**,  \n",
        "   - 10 **pridjeva**.  \n",
        "4. Prikaži rezultate u **tri odvojene tablice** ili **grafovima** (koristi `pandas` i `matplotlib`).  \n",
        "5. Usporedi govore i pokušaj zaključiti:\n",
        "   - Koji govor je “pozitivniji” (više koristi riječi poput *hope*, *future*, *together*)  \n",
        "   - Koji je “defanzivniji” ili “konfliktniji” (više koristi riječi poput *fight*, *challenge*, *threat*).  \n",
        "6. Na kraju napiši **kratki zaključak (2–3 rečenice)**: kako se teme razlikuju i što dominira u svakom govoru.\n",
        "\n",
        "---\n",
        "\n",
        "**Cilj:**  \n",
        "Ovim zadatkom studenti povezuju sve što su naučili, obradu, analizu i interpretaciju teksta, u jednu cjelinu, simulirajući osnovnu NLP analizu stvarnih podataka.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "Ck_vcgjYb9IN"
      },
      "id": "Ck_vcgjYb9IN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_A = \"\"\"My fellow citizens, today we gather not as strangers, but as a community united by our shared hopes and dreams.\n",
        "We stand at the dawn of a new era—one built on innovation, cooperation, and the unshakable belief in the potential of our people.\n",
        "The challenges before us are great, but so too is our courage and creativity.\n",
        "We will invest in education, protect our planet, and empower every individual to shape their own destiny.\n",
        "\n",
        "Let us build bridges, not walls; extend hands, not fists.\n",
        "Together, we can create a nation where opportunity is not limited to the few, but shared by all.\n",
        "Our strength lies not in fear, but in faith—in each other, in our values, and in the bright future we will create together.\n",
        "\n",
        "Let this be the generation that chooses unity over division, progress over stagnation, and hope over despair.\n",
        "Let this be the generation that dares to dream boldly, that embraces change, and that lifts one another up rather than tearing each other down.\n",
        "\n",
        "We will work to expand access to healthcare, to ensure that no family has to choose between medicine and food.\n",
        "We will support our teachers, invest in our children, and build schools that prepare every young mind for the world of tomorrow.\n",
        "We will encourage clean energy, sustainable development, and responsible stewardship of the natural resources entrusted to us.\n",
        "\n",
        "And above all, we will choose compassion—compassion for our neighbors, for our communities, and for those whose voices too often go unheard.\n",
        "Our nation is strongest when every citizen feels seen, valued, and empowered.\n",
        "\n",
        "Together, we will write a new chapter in our nation’s story—one defined not by fear or division, but by courage, unity, and purpose.\n",
        "A future filled with opportunity is within our reach, and it is a future we will build hand in hand.\n",
        "Let us move forward with confidence, with optimism, and with unwavering hope in all that we can achieve—together.\n",
        "\"\"\"\n",
        "\n",
        "text_B = \"\"\"My fellow citizens, the world we face today is uncertain and full of danger.\n",
        "Across the globe, our values are challenged, our security is tested, and our freedom is under threat.\n",
        "We cannot afford complacency or hesitation.\n",
        "We must strengthen our defenses, protect our borders, and ensure the safety of our families and our future.\n",
        "\n",
        "Our enemies seek to divide us, to weaken our resolve, and to spread fear and chaos.\n",
        "But we will not yield.\n",
        "We will act with determination, discipline, and strength.\n",
        "Every citizen has a role to play in defending our nation and preserving our way of life.\n",
        "\n",
        "We must increase our vigilance, enhance our intelligence capabilities, and give our armed forces the tools they need to counter every threat.\n",
        "We must stand firm against those who wish to undermine our democracy, whether they act from within or from beyond our borders.\n",
        "\n",
        "Let us face the challenges before us with courage, and together ensure that the next generation inherits not fear, but freedom—not weakness, but resilience.\n",
        "We will confront extremism wherever it appears.\n",
        "We will push back against hostile powers seeking to disrupt our alliances.\n",
        "We will safeguard our economy from manipulation and ensure that our industries cannot be exploited by those who do not share our values.\n",
        "\n",
        "The dangers we confront are real, and they are growing.\n",
        "Cyberattacks, disinformation campaigns, and coordinated acts of aggression threaten our stability.\n",
        "We cannot ignore these warnings; we must respond with unity and unwavering resolve.\n",
        "\n",
        "We will reinforce our border security, support law enforcement, and empower our military to defend every inch of our homeland.\n",
        "We will stand shoulder to shoulder, refusing to be intimidated, refusing to be divided, and refusing to surrender to forces that thrive on fear.\n",
        "\n",
        "Together, we will ensure that our nation remains safe, strong, and unbroken.\n",
        "We will rise to meet every threat, overcome every obstacle, and protect the sacred freedoms that define us.\n",
        "This is our duty, our responsibility, and our promise to all who come after us.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "DF8ymaqucBd8"
      },
      "id": "DF8ymaqucBd8",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}